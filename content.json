{"meta":{"title":"下个路口见","subtitle":"脚步匆匆,只是不知下一站会在哪里... 一切只是开始,一切也终将继续","description":"不同的生活,带来不同的际遇,福祸好歹,终会积累成经历的一种,脚步匆匆,只是不知下一站会在哪里... 一切只是开始,一切也终将继续","author":"Cydeer","url":"http://www.merlin4io.com"},"pages":[],"posts":[{"title":"Spring Boot 笔记","slug":"Spring-Boot-笔记","date":"2018-09-04T13:50:30.000Z","updated":"2018-09-05T15:16:37.000Z","comments":true,"path":"2018/09/04/Spring-Boot-笔记/","link":"","permalink":"http://www.merlin4io.com/2018/09/04/Spring-Boot-笔记/","excerpt":"项目中一直在用Spring Boot,只是一直没有做系统的学习,各方面的使用都有涉及,但是不全面,这两天看到了一个比较全的博客,但是分了二十多篇,感觉有点冗杂,于是,想自己做一份记录,方便后面的查看.所以,这篇文章出现在了这里,记录比较简单.不喜勿喷.下面的内容会首先构建一个最小的可运行demo,一步一步添加内容.","text":"项目中一直在用Spring Boot,只是一直没有做系统的学习,各方面的使用都有涉及,但是不全面,这两天看到了一个比较全的博客,但是分了二十多篇,感觉有点冗杂,于是,想自己做一份记录,方便后面的查看.所以,这篇文章出现在了这里,记录比较简单.不喜勿喷.下面的内容会首先构建一个最小的可运行demo,一步一步添加内容. 配置文件可以在项目结构中的resources下面看到application.properties文件,该文件作为项目的配置文件,一些通用配置可以配置在这里,比如项目名称等着里只是放置各个环境通用,无隐私信息(用户名,密码,ip相关).当然配置文件也可以放置到其他位置,下面来罗列可以放置的位置以及生效的优先级.排在前面的优先级越高,不过一般情况下我们不会这么做. 当前目录下的一个/config子目录 当前目录 一个classpath下的/config包 classpath根路径（root） 一些常用的配置如下 1234#端口配置：server.port=8090#时间格式化spring.jackson.date-format=yyyy-MM-dd HH:mm:ss 配置文件中可以定义一些随机说,范围值: 123cydeer.number=$&#123;random.int&#125;cydeer.number.less.than.ten=$&#123;random.int(10)&#125;cydeer.number.in.range=$&#123;random.int[1024,65536]&#125; 使用的时候可以通过注解:@Value(value = “${cydeer.number}”)来使用,也可以使用@ConfigurationProperties( prefix = “cydeer.user”) 来注入一系列属性到bean中. 1234cydeer.user.id=64cydeer.user.name=Cydeercydeer.user.hobby[0]=看电影cydeer.user.hobby[1]=旅游 配置文件还可以使用YAML方式,该方式的可读性更高,官方推荐使用该方式,使用该种方式需要注意: 注意写法,冒号后面要加个空格 该方式不能够和@PropertySource(自定义配置文件位置)一起使用 相同前缀的key需要配置在一起. 多环境支持只需要一个配置文件 多环境支持application-{profile}.properties，{profile}对应你的环境标识,新建文件到resources文件夹下面即可,如： 1234application-dev.properties：开发环境application-test.properties：测试环境application-pre.properties：预发环境application-prod.properties：生产环境 启用对应环境配置文件的方式有以下三种: 在application.properties配置spring.profiles.active为对应 ${profile}即可比如:spring.profiles.active=dev,则启用了开发环境 命令行方式激活不同环境配置 java -jar xxx.jar –spring.profiles.active=dev jvm参数重配置 java -Dspring.profiles.active=dev -jar xxx.jar 日志文件推荐使用logback.spring boot默认会加载classpath:logback-spring.xmlapplication-${profile}.properties中可以指定日志级别,那些包下面的日志的输出级别.logging.level.com.cydeer.core=info:com.cydeer.core包下所有class高于info级别的都会输出.logging.level.org.springframework=WARN:org.springframework包下的class高于WARN级别输出.还可以配置日志的目录,或者文件logging.path=./logslogging.file=my.log 常用注解 @SpringBootApplication此注解是个组合注解，包括了@SpringBootConfiguration、@EnableAutoConfiguration和@ComponentScan注解。 @SpringBootConfiguration 继承至@Configuration，对于熟悉spring的开发者而言，此标注当前类是配置类，并会将当前类内声明的一个或多个以@Bean注解标记的方法的实例纳入到srping容器中，并且实例名就是方法名。 @EnableAutoConfiguration 这个注解就是springboot能自动进行配置的魔法所在了。主要是通过此注解，能所有符合自动配置条件的bean的定义加载到spring容器中，比如根据spring-boot-starter-web ，来判断你的项目是否需要添加了webmvc和tomcat，就会自动的帮你配置web项目中所需要的默认配置. @ComponentScan 这个熟悉spring的开发者也应该熟悉，会扫描当前包及其子包下被@Component，@Controller，@Service，@Repository等注解标记的类并纳入到spring容器中进行管理。 @RestController 是Spring4之后加入的注解，原来在@Controller中返回json需要@ResponseBody来配合，如果直接用@RestController替代@Controller就不需要再配置@ResponseBody，默认返回json格式。而@Controller是用来创建处理http请求的对象，一般结合@RequestMapping使用。 @RequestMapping,@RequestBody,@PathVariable、@RequestParam、@RequestAttribute@Component、@Service、@Repository 异常处理在项目中,请求处理过程中,出现异常是经常出现的,有的时候我们会在系统内容定义统一异常,通过该种方式,可以快速的中断流程,还有一些异常情况是未知的,比如说数据库连接失败异常,等等,这些异常一般情况下都是不应该返回给系统之外的,如果系统提供API的话,一般还会有固定的数据格式,突然给别人一个异常,给别人的感觉就是这个网站(服务端)很 low,调用方也会很懵逼的.所以一般系统中都会做一个异常捕获或者二次处理转化. 统一异常一般分为两种情况,使用运行时异常或者受检异常,各有各的好处,运行时异常使用起来方便,调用房不需要处理,交给对外统一异常拦截来处理,该种方式的缺点是,如果处理流程是异步处理的,那么异步代码块就需要在外层添加一个异常处理逻辑(这一部分往往很多人会遗忘,因为是非受检异常).受检异常的优点是,外部调用者明确知道该方法可能会有异常,而且必须处理异常,这是该种方式的优点,同样也是缺点,很多情况下都是,捕获到这种异常,然后就直接抛出去了,每个调用的地方都需要来处理. Spring Boot中异常情况下默认会跳转值/error请求进行错误的展现,根据不同的Content-Type展现不同的错误结果,如json请求时,直接返回json格式参数. 我们可以自定义错误页面,方式如下: 12345678910111213141516@Controller@RequestMapping(value = &quot;error&quot;)public class BaseErrorController implements ErrorController &#123;private static final Logger logger = LoggerFactory.getLogger(BaseErrorController.class); @Override public String getErrorPath() &#123; logger.info(&quot;出错啦！进入自定义错误控制器&quot;); return &quot;error/error&quot;; &#125; @RequestMapping public String error() &#123; return getErrorPath(); &#125;&#125; 也可以通过添加自定义错误页面 html静态页面:放到resources/public/error/ 即可, 如添加404页面:resources/public/error/404.html, 503页面:resources/public/error/503.html. 模版引擎页面:在templates/error/下定义 如添加5xx页面： templates/error/5xx.ftl 注意：templates/error/ 这个的优先级比较 resources/public/error/高 也可以通过注解@ControllerAdvice统一异常处理 @ExceptionHandler 可以指定对应的异常处理方式@ResponseStatus控制这种异常的返回状态码是什么 123456789101112131415161718192021222324252627282930313233/** * 统一异常处理 * * @param exception * exception * @return */ @ExceptionHandler(&#123; RuntimeException.class &#125;) @ResponseStatus(HttpStatus.OK) public ModelAndView processException(RuntimeException exception) &#123; logger.info(&quot;自定义异常处理-RuntimeException&quot;); ModelAndView m = new ModelAndView(); m.addObject(&quot;roncooException&quot;, exception.getMessage()); m.setViewName(&quot;error/500&quot;); return m; &#125; /** * 统一异常处理 * * @param exception * exception * @return */ @ExceptionHandler(&#123; Exception.class &#125;) @ResponseStatus(HttpStatus.OK) public ModelAndView processException(Exception exception) &#123; logger.info(&quot;自定义异常处理-Exception&quot;); ModelAndView m = new ModelAndView(); m.addObject(&quot;roncooException&quot;, exception.getMessage()); m.setViewName(&quot;error/500&quot;); return m; &#125;","categories":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"http://www.merlin4io.com/categories/杂七杂八/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.merlin4io.com/tags/Spring-Boot/"},{"name":"异常处理","slug":"异常处理","permalink":"http://www.merlin4io.com/tags/异常处理/"},{"name":"统一异常","slug":"统一异常","permalink":"http://www.merlin4io.com/tags/统一异常/"},{"name":"Spring常用注解","slug":"Spring常用注解","permalink":"http://www.merlin4io.com/tags/Spring常用注解/"}]},{"title":"JVM共享内存结构以及内存分配策略","slug":"JVM共享内存结构以及内存分配策略","date":"2018-07-27T15:09:47.000Z","updated":"2018-08-02T11:02:18.000Z","comments":true,"path":"2018/07/27/JVM共享内存结构以及内存分配策略/","link":"","permalink":"http://www.merlin4io.com/2018/07/27/JVM共享内存结构以及内存分配策略/","excerpt":"JVM内存区分总体可以分为五个部分,具体可以参考上一篇 JVM内存结构分析.但是通常情况下,JVM内存主要以线程共享内存和单程独享内存来作区分,上一篇也讲过,JVM五个区域中,堆区和方法区都属于线程共享区域,而程序计数器,虚拟机栈,本地方法栈为线程独享区域.如下图所示:","text":"JVM内存区分总体可以分为五个部分,具体可以参考上一篇 JVM内存结构分析.但是通常情况下,JVM内存主要以线程共享内存和单程独享内存来作区分,上一篇也讲过,JVM五个区域中,堆区和方法区都属于线程共享区域,而程序计数器,虚拟机栈,本地方法栈为线程独享区域.如下图所示: 对象优先分配在线程的本地分配缓冲区在前面我们提到，每个线程可以在堆中预先分配得到一片区域，作为本地线程分配缓冲区（TLAB）。当该线程执行时，有对象创建的话，就在该线程的TLAB中分配内存。当该线程的TLAB用完了才申请堆中的空闲内存。 二：堆中优先分配Eden 大多数情况下，对象都在新生代的Eden区中分配内存。而因为大部分的对象都是“朝生夕死”的，所以新生代又会频繁进行垃圾回收。 三：大对象直接进入老年代 需要大量连续空间的对象，如：长字符串、数组等，会直接在老年代分配内存。这是因为，这样可以避免在新生代区频繁的GC时发生大量的内存赋值（新生代的GC是采用复制算法的）。 四：长期存活的对象“晋入”老年代 新生代中经历了多次GC仍然存活的对象，当年龄达到一定程度（默认15）时就会晋升到老年代。 为了更好地适应内存情况，虚拟机不是要求对象必须到达阀值才可晋升老年代的，而是采用动态年龄判定的方法：如果Servivor空间中相同年龄的对象大小大于Servivor空间的一般时，由于下一次的MinorGC时，这些对象如果仍然存活的话，复制到ToServivor空间时就放不下了。所以，在本次GC时就可以把这些对象以及年龄大于等于这些对象的直接进入老年代。 在MinorGC时，如果Eden和FromServivor中存活的对象在复制到ToServivor时放不下了，也会直接分配到老年代。 五：空间分配担保 在MinorGC之前，会先检查老年代最大可用空间是否可以容纳新生代所有对象（防止新生代全部晋升时放不下），如果可以容纳，则MinorGC可以安全执行。否则，检查是否允许担保失败，是则检查老年代最大可用空间是否大于历次晋升到老年代的对象的平均大小，是则尝试进行MinorGC；小于或者MinorGC失败，则会发起一次FullGC清理老年代。","categories":[{"name":"JVM系列","slug":"JVM系列","permalink":"http://www.merlin4io.com/categories/JVM系列/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.merlin4io.com/tags/JVM/"},{"name":"内存分配策略","slug":"内存分配策略","permalink":"http://www.merlin4io.com/tags/内存分配策略/"}]},{"title":"JVM内存结构分析","slug":"JVM内存结构分析","date":"2018-07-26T10:58:21.000Z","updated":"2018-07-28T01:25:10.000Z","comments":true,"path":"2018/07/26/JVM内存结构分析/","link":"","permalink":"http://www.merlin4io.com/2018/07/26/JVM内存结构分析/","excerpt":"Java代码是要运行在虚拟机上的,而虚拟机在执行Java程序的过程中会把所管理的内存划分为若干个不同的数据区域,这些区域都有各自的用途,其中有些区域随着虚拟机进程的启动而存在,有些区域则依赖用户线程的启动和结束而建立和销毁.JVM内存结构主要分为五个部分,方法区(Java8之后改为元空间),堆区,虚拟机栈,本地方法栈,程序计数器.其中方法区和堆区是所有线程共享的数据区,虚拟机栈,本地方法栈,程序计数器为线程隔离的数据区.","text":"Java代码是要运行在虚拟机上的,而虚拟机在执行Java程序的过程中会把所管理的内存划分为若干个不同的数据区域,这些区域都有各自的用途,其中有些区域随着虚拟机进程的启动而存在,有些区域则依赖用户线程的启动和结束而建立和销毁.JVM内存结构主要分为五个部分,方法区(Java8之后改为元空间),堆区,虚拟机栈,本地方法栈,程序计数器.其中方法区和堆区是所有线程共享的数据区,虚拟机栈,本地方法栈,程序计数器为线程隔离的数据区. JVM内存结构图 PC寄存器(程序计数器)程序计数器（Program Counter Register）也叫PC寄存器,是当前线程所执行的字节码的行号指示器.字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令,分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成.每条线程都需要有一个独立的程序计数器. 如果线程正在执行的是一个Java方法,这个计数器记录的是正在执行的虚拟机字节码指令的地址;如果正在执行的是Native方法,这个计数器值则为空（Undefined）.此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域. Java虚拟机栈Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的,它的生命周期与线程相同.虚拟机栈描述的是Java方法执行的内存模型:每个方法在执行的同时都会创建一个栈帧（Stack Frame [1] ）用于存储局部变量表、操作数栈、动态链接、方法出口等信息.每一个方法从调用直至执行完成的过程,就对应着一个栈帧在虚拟机栈中入栈到出栈的过程. 每个线程都会创建一个Java栈,每个Java栈中有多个栈帧,当线程中调用一个方法,就会在Java栈中存放一个栈帧,一个栈帧包括内部变量（局部变量）,操作栈,返回值信息.Java栈的栈顶为活动的栈帧（方法）,当方法再次调用其他的方法就会在栈顶在创建一个新的栈帧,每个栈帧的操作栈只能访问自己自己栈帧的局部变量.java栈的数据是不共享的所以不存在同步锁问题. 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身,可能是一个指向对象起始地址的引用指针,也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）. 在Java虚拟机规范中,对这个区域规定了两种异常状况:如果线程请求的栈深度大于虚拟机所允许的深度,将抛出StackOverflowError异常;如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展,只不过Java虚拟机规范中也允许固定长度的虚拟机栈）,如果扩展时无法申请到足够的内存,就会抛出OutOfMemoryError异常。 本地方法栈本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常相似的,它们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务,而本地方法栈则为虚拟机使用到的Native方法服务.在虚拟机规范中对本地方法栈中方法使用的语言、使用方式与数据结构并没有强制规定,因此具体的虚拟机可以自由实现它.甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一.与虚拟机栈一样,本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常. Java堆Java堆是被所有线程共享的一块内存区域,在虚拟机启动时创建.此内存区域的唯一目的就是存放对象实例,几乎所有的对象实例都在这里分配内存. Java堆是垃圾收集器管理的主要区域,从内存回收的角度来看,由于现在收集器基本都采用分代收集算法,所以Java堆中还可以细分为:新生代和老年代。 根据Java虚拟机规范的规定,Java堆可以处于物理上不连续的内存空间中,只要逻辑上是连续的即可,就像我们的磁盘空间一样.在实现时,既可以实现成固定大小的,也可以是可扩展的,不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）.如果在堆中没有内存完成实例分配,并且堆也无法再扩展时,将会抛出OutOfMemoryError异常. 方法区(元空间)方法区（Method Area）与Java堆一样,是各个线程共享的内存区域,它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据.可以通过maxPerm参数设置大小. 对于习惯在HotSpot虚拟机上开发、部署程序的开发者来说,很多人都更愿意把方法区称为“永久代”（Permanent Generation）,本质上两者并不等价,仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区,或者说使用永久代来实现方法区而已,这样HotSpot的垃圾收集器可以像管理Java堆一样管理这部分内存,能够省去专门为方法区编写内存管理代码的工作.对于其他虚拟机（如BEA JRockit、IBM J9等）来说是不存在永久代的概念的. 根据Java虚拟机规范的规定,当方法区无法满足内存分配需求时,将抛出OutOfMemoryError异常. 绝大部分 Java 程序员应该都见过 “java.lang.OutOfMemoryError: PermGen space ”这个异常.这里的 “PermGen space”其实指的就是方法区.不过方法区和“PermGen space”又有着本质的区别.前者是 JVM 的规范,而后者则是 JVM 规范的一种实现,并且只有 HotSpot 才有 “PermGen space”,而对于其他类型的虚拟机,如 JRockit（Oracle）、J9（IBM） 并没有“PermGen space”.由于方法区主要存储类的相关信息,所以对于动态生成类的情况比较容易出现永久代的内存溢出.最典型的场景就是,在 jsp 页面比较多的情况，容易出现永久代内存溢出.也通过动态生成类来模拟 “PermGen space”的内存溢出. 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分,也不是Java虚拟机规范中定义的内存区域. 在JDK 1.4中新加入了NIO（New Input/Output）类,引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式,它可以使用Native函数库直接分配堆外内存,然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作.这样能在一些场景中显著提高性能,因为避免了在Java堆和Native堆中来回复制数据. 显然，本机直接内存的分配不会受到Java堆大小的限制,但是,既然是内存,肯定还是会受到本机总内存（包括RAM以及SWAP区或者分页文件）大小以及处理器寻址空间的限制.服务器管理员在配置虚拟机参数时,会根据实际内存设置-Xmx等参数信息,但经常忽略直接内存,使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制）,从而导致动态扩展时出现OutOfMemoryError异常. 元空间(Java1.8)其实，移除永久代的工作从JDK1.7就开始了.JDK1.7中,存储在永久代的部分数据就已经转移到了Java Heap或者是 Native Heap.但永久代仍存在于JDK1.7中,并没完全移除,譬如符号引用(Symbols)转移到了native heap;字面量(interned strings)转移到了java heap;类的静态变量(class statics)转移到了java heap. 元空间的本质和永久代类似,都是对JVM规范中方法区的实现.不过元空间与永久代之间最大的区别在于:元空间并不在虚拟机中,而是使用本地内存.因此,默认情况下,元空间的大小仅受本地内存限制,但可以通过以下参数来指定元空间的大小:-XX:MetaspaceSize,初始空间大小,达到该值就会触发垃圾收集进行类型卸载,同时GC会对该值进行调整:如果释放了大量的空间,就适当降低该值;如果释放了很少的空间,那么在不超过MaxMetaspaceSize时,适当提高该值.-XX:MaxMetaspaceSize,最大空间,默认是没有限制的.","categories":[{"name":"JVM系列","slug":"JVM系列","permalink":"http://www.merlin4io.com/categories/JVM系列/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.merlin4io.com/tags/JVM/"},{"name":"内存管理","slug":"内存管理","permalink":"http://www.merlin4io.com/tags/内存管理/"}]},{"title":"负载均衡的常用算法","slug":"负载均衡的常用算法","date":"2018-07-24T15:19:51.000Z","updated":"2018-07-25T15:13:24.000Z","comments":true,"path":"2018/07/24/负载均衡的常用算法/","link":"","permalink":"http://www.merlin4io.com/2018/07/24/负载均衡的常用算法/","excerpt":"负载均衡,指由多台服务器组成一个服务器集群,每台服务器都具有等价的地位,可以单独对外提供服务,无需互相之间协调,负载均衡就是把外部的请求,均匀的分配到集群中的某一台服务器上,而收到请求的服务器,处理请求,并返回对应的结果.负载均衡可以分担服务器压力,提供服务器的性能,解决大量兵法访问服务问题.这种集群技术可以用最少的资源获得接近大型主机的性能.,负载均衡有很多的算法,常用的有以下几种:轮询算法,加权轮询算法,随机算法,加权随机算法,源地址哈希算法,最小连接数算法.","text":"负载均衡,指由多台服务器组成一个服务器集群,每台服务器都具有等价的地位,可以单独对外提供服务,无需互相之间协调,负载均衡就是把外部的请求,均匀的分配到集群中的某一台服务器上,而收到请求的服务器,处理请求,并返回对应的结果.负载均衡可以分担服务器压力,提供服务器的性能,解决大量兵法访问服务问题.这种集群技术可以用最少的资源获得接近大型主机的性能.,负载均衡有很多的算法,常用的有以下几种:轮询算法,加权轮询算法,随机算法,加权随机算法,源地址哈希算法,最小连接数算法. 接下来的算法讨论皆基于如下机器列表:12345678910111213141516171819202122232425262728package com.cydeer.demo.route;import java.util.HashMap;/** * @author zhangsong Created on 2018/7/25 22:27 */public class ServerIpMap &#123; /** 待路由的服务器列表，Key代表服务器ip，Value代表该该服务器ip的权重 */ public static HashMap&lt;String, Integer&gt; serverWeightMap = new HashMap&lt;&gt;(); static &#123; serverWeightMap.put(\"192.168.1.100\", 1); serverWeightMap.put(\"192.168.1.101\", 1); /** 权重为4 */ serverWeightMap.put(\"192.168.1.102\", 4); serverWeightMap.put(\"192.168.1.103\", 1); serverWeightMap.put(\"192.168.1.104\", 1); /** 权重为3 */ serverWeightMap.put(\"192.168.1.105\", 3); serverWeightMap.put(\"192.168.1.106\", 1); /** 权重为2 */ serverWeightMap.put(\"192.168.1.107\", 2); serverWeightMap.put(\"192.168.1.108\", 1); serverWeightMap.put(\"192.168.1.109\", 1); serverWeightMap.put(\"192.168.1.110\", 1); &#125;&#125; 轮询、加权轮询算法轮询算法是指:将请求按顺序轮流地分配到后端服务器上,它均衡地对待后端的每一台服务器,而不关心服务器实际的连接数和当前的系统负. 算法实现:1234567891011121314151617181920212223242526272829303132package com.cydeer.demo.route;import java.util.*;/** * @author zhangsong Created on 2018/7/25 22:30 */public class RoundRobin &#123; /** * 当前轮询的下标 */ private static Integer pos = 0; public static String getServer() &#123; // 重建一个Map，避免服务器的上下线导致的并发问题 Map&lt;String, Integer&gt; serverMap = new HashMap&lt;&gt;(); serverMap.putAll(ServerIpMap.serverWeightMap); // 取得Ip地址List Set&lt;String&gt; keySet = serverMap.keySet(); List&lt;String&gt; keyList = new ArrayList&lt;&gt;(keySet); String server; synchronized (pos) &#123; if (pos &gt; keySet.size()) &#123; pos = 0; &#125; server = keyList.get(pos); pos++; &#125; return server; &#125;&#125; 加权轮询算法是指:不同的后端服务器可能机器的配置和当前系统的负载并不相同,因此它们的抗压能力也不相同,给配置高、负载低的机器配置更高的权重,让其处理更多的请求,而配置低、负载高的机器,给其分配较低的权重,降低其系统负载.加权轮询算法的存在就能很好地解决这一问题,将请求按照顺序且按照权重分配到后端服务器. 加权轮询算法的实现:1234567891011121314151617181920212223242526272829303132333435package com.cydeer.demo.route;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;/** * @author zhangsong Created on 2018/7/25 22:38 */public class WeightRoundRobin &#123; private static Integer pos; public static String getServer() &#123; // 重建一个Map，避免服务器的上下线导致的并发问题 Map&lt;String, Integer&gt; serverMap = new HashMap&lt;&gt;(); serverMap.putAll(ServerIpMap.serverWeightMap); List&lt;String&gt; serverList = new ArrayList&lt;&gt;(); serverMap.forEach((serverId, weight) -&gt; &#123; for (int i = 0; i &lt; weight; i++) &#123; serverList.add(serverId); &#125; &#125;); String server; synchronized (pos) &#123; if (pos &gt; serverList.size()) &#123; pos = 0; &#125; server = serverList.get(pos); pos++; &#125; return server; &#125;&#125;两种算法的实现代码相同,不同的是,对应的权重不同,轮询,可以当作是加权轮训的特殊情况(权重都为1的情况). 随机、加权随机算法随机算法是指通过系统的随机算法,根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问,由概率统计理论可以得知,随着客户端调用服务端的次数增多,其实际效果越来越接近于平均分配调用量到后端的每一台服务器,也就是轮询的结果. 随机算法实现： 1234567891011121314151617181920212223package com.cydeer.demo.route;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;/** * @author zhangsong Created on 2018/7/25 22:49 */public class RandomRobin &#123; public static String getServer() &#123; // 重建一个Map，避免服务器的上下线导致的并发问题 Map&lt;String, Integer&gt; serverMap = new HashMap&lt;&gt;(); serverMap.putAll(ServerIpMap.serverWeightMap); // 取得Ip地址List List&lt;String&gt; keyList = new ArrayList&lt;&gt;(serverMap.keySet()); java.util.Random random = new java.util.Random(); int randomPos = random.nextInt(keyList.size()); return keyList.get(randomPos); &#125;&#125; 加权随机算法与加权轮询法一样,加权随机法也根据后端机器的配置,系统的负载分配不同的权重,不同的是,它是按照权重随机请求后端服务器,而非顺序. 加权随机算法实现：123456789101112131415161718192021222324package com.cydeer.demo.route;import java.util.*;/** * @author zhangsong Created on 2018/7/25 22:53 */public class WeightRandomRobin &#123; public static String getServer() &#123; // 重建一个Map，避免服务器的上下线导致的并发问题 Map&lt;String, Integer&gt; serverMap = new HashMap&lt;&gt;(); serverMap.putAll(ServerIpMap.serverWeightMap); // 取得Ip地址List List&lt;String&gt; serverList = new ArrayList&lt;&gt;(); serverMap.forEach((serverId, weight) -&gt; &#123; for (int i = 0; i &lt; weight; i++) &#123; serverList.add(serverId); &#125; &#125;); Random random = new java.util.Random(); int randomPos = random.nextInt(serverList.size()); return serverList.get(randomPos); &#125;&#125; 源地址哈希算法源地址哈希是指对客户端的地址通过哈希函数计算得到的一个数值,然后对服务器总数取模,得到的结果就是服务器的序号,源地址hash作为负载算法,同一ip客户端,当后端的服务器列表顺序不变,它每次都会映射到同一台后端服务器访问.这样如果后端服务器不变,可以保持客户端和服务端的session会话,集群session解决方案之一就是源地址hash路由算法. 源地址哈希算法实现:12345678910111213141516171819202122232425262728package com.cydeer.demo.route;import java.util.ArrayList;import java.util.HashMap;import java.util.Map;/** * @author zhangsong Created on 2018/7/25 23:02 */public class HashRobin &#123; /** * 在Web应用中可通过HttpServlet的getRemoteIp方法获取 * * @param remoteIp * @return */ public static String getServer(String remoteIp) &#123; // 重建一个Map，避免服务器的上下线导致的并发问题 Map&lt;String, Integer&gt; serverMap = new HashMap&lt;&gt;(); serverMap.putAll(ServerIpMap.serverWeightMap); // 取得Ip地址List List&lt;String&gt; keyList = new ArrayList&lt;&gt;(serverMap.keySet()); int hashCode = remoteIp.hashCode(); int serverListSize = keyList.size(); int serverPos = hashCode % serverListSize; return keyList.get(serverPos); &#125;&#125; 最小连接数算法前面几种方法费尽心思来实现服务消费者请求次数分配的均衡,当然这么做是没错的,可以为后端的多台服务器平均分配工作量,最大程度地提高服务器的利用率,但是实际情况是否真的如此?实际情况中,请求次数的均衡真的能代表负载的均衡吗?这是一个值得思考的问题. 上面的问题,再换一个角度来说就是:以后端服务器的视角来观察系统的负载,而非请求发起方来观察.最小连接数法便属于此类 最小连接数法比较灵活和智能是最接近真实情况,最合理的负载算法.它根据后端服务器的当前连接情况,动态的选择其中当前连接数最小的一台服务器来处理请求.尽可能的提高后端服务器的利用率,将负载合理的分流到每一台服务器.","categories":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"http://www.merlin4io.com/categories/杂七杂八/"}],"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"http://www.merlin4io.com/tags/负载均衡/"},{"name":"路由","slug":"路由","permalink":"http://www.merlin4io.com/tags/路由/"}]},{"title":"Spring boot 和Mybaties整合","slug":"Spring-boot-和Mybaties整合","date":"2017-12-07T14:31:22.000Z","updated":"2018-07-24T14:57:41.000Z","comments":true,"path":"2017/12/07/Spring-boot-和Mybaties整合/","link":"","permalink":"http://www.merlin4io.com/2017/12/07/Spring-boot-和Mybaties整合/","excerpt":"简单记录一下spring boot 和mybaties整合的一个过程，记录不全的地方可以参看 Spring Boot 整合 MyBatis spring boot 集成 mybatis：如何优雅的使用mybatis spring boot集成mybatis+事务控制 这几篇都可以看看。","text":"简单记录一下spring boot 和mybaties整合的一个过程，记录不全的地方可以参看 Spring Boot 整合 MyBatis spring boot 集成 mybatis：如何优雅的使用mybatis spring boot集成mybatis+事务控制 这几篇都可以看看。pom 配置文件 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.cydeer&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 配置文件application.properties spring.datasource.url=jdbc:mysql://localhost:3306/dev?useUnicode=true&amp;amp;characterEncoding=UTF-8 spring.datasource.username=dev spring.datasource.password=dev spring.datasource.driver-class-name=com.mysql.jdbc.Driver # 自定义mybaties设置，可以不需要 mybatis.config-locations=classpath:mybatis/mybatis-config.xml # 自定义mapper的xml文件位置 按需要配置，没有复杂的sql就不需要这个配置 mybatis.mapperLocations=classpath:mybatis/xml/*.xml 启动类配置 @SpringBootApplication // 自定义mapper存放位置 @MapperScan(&quot;com.cydeer.mapper&quot;) public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); } } mapper文件 package com.cydeer.mapper; import com.cydeer.dao.BannerInfo; import org.apache.ibatis.annotations.Select; import java.util.List; public interface BannerInfoMapper { // 注解式sql @Select(&quot;select id,image_url,title,content,type,status,index_value,deleted,create_time from banner_info where id = #{id}&quot;) BannerInfo findBannerById(Integer id); // xml文件式sql List&lt;BannerInfo&gt; listAllBannerInfoByQueryParam(); } mapper对应的xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot; &gt; &lt;mapper namespace=&quot;com.cydeer.mapper.BannerInfoMapper&quot;&gt; &lt;select id=&quot;listAllBannerInfoByQueryParam&quot; resultType=&quot;com.cydeer.dao.BannerInfo&quot;&gt; select id,image_url,title,type,status,index_value,create_time,update_time from banner_info where deleted = 0 order by update_time desc limit 100 &lt;/select&gt; &lt;/mapper&gt; testCase内容 package com.cydeer.test; import com.cydeer.DemoApplication; import com.cydeer.mapper.BannerInfoMapper; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; import javax.annotation.Resource; /** * Created by zhangsong on 2017/8/3. */ @RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = DemoApplication.class) public class UserDaoTest { @Resource private BannerInfoMapper bannerInfoMapper; @Test public void testBookSelect(){ System.out.println(bannerInfoMapper.findBannerById(1)); System.out.println(bannerInfoMapper.listAllBannerInfoByQueryParam()); } }","categories":[],"tags":[]},{"title":"Redis哨兵模式配置","slug":"Redis哨兵模式配置","date":"2017-11-27T04:56:04.000Z","updated":"2017-11-27T05:03:07.000Z","comments":true,"path":"2017/11/27/Redis哨兵模式配置/","link":"","permalink":"http://www.merlin4io.com/2017/11/27/Redis哨兵模式配置/","excerpt":"","text":"安装reids之后启动检测redis安装是否成功。 修改redis.conf文件，bind 127.0.0.1不需要配置密码。 copy redis.conf 文件，修改端口，设置bind 127.0.0.1 设置slaveof 127.0.0.1 6379 copy redis.conf 文件，修改端口，设置bind 127.0.0.1 设置slaveof 127.0.0.1 6379 配置redis_sentinel.conf文件，监听同一个masterport 26379daemonize yesprotected-mode nosentinel monitor dazi_master 127.0.0.1 6379 2 copy 修改port 26380其他不修改port 26380daemonize yesprotected-mode nosentinel monitor dazi_master 127.0.0.1 6379 2 copy 修改port 26381其他不修改port 26381daemonize yesprotected-mode nosentinel monitor dazi_master 127.0.0.1 6379 2","categories":[],"tags":[]},{"title":"Spring Aop源码解析","slug":"Spring-Aop源码解析","date":"2017-09-11T04:57:12.000Z","updated":"2017-09-11T06:54:09.000Z","comments":true,"path":"2017/09/11/Spring-Aop源码解析/","link":"","permalink":"http://www.merlin4io.com/2017/09/11/Spring-Aop源码解析/","excerpt":"","text":"配置文件加载要启用Aop，我们一般会在配置文件中配置,而Spring启动的时候，解析xml文件的时候，根据Namespace确定用自身的解析器还是用自定义的，而使用aop就是使用自定义的AopNamespeceHandler，这个handler中会设置aspectj-autoproxy的解析使用AspectjAutoProxyBeanDefinitionParser解析器解析。进入AspectjAutoProxyBeanDefinitionParser解析器后，会把解析请求交给AopNamespaceUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary去处理，这里面会先用AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary去处理，然后这里面有调用自身的方法registerOrEscalateApcAsRequired注册或者升级AnnotationAwareAspectJAutoProxyCreator，对于aop的实现，基本是靠AnnotationAwraeAspectJAutoProxyCreator去完成的，它可以根据pointcut注解定义的切点来代理相匹配的bean。 AopConfigUtils的registerAspectJAnnotationAutoProxyCreatorIfNecessary的方法处理之后会调用useClassProxyingIfNecessary处理proxy-target-class以及expose-proxy属性。如果proxy-target-class设置为true的话，那么会强制使用CDLIB代理，否则会按照是否有接口来确定使用jdb动态代理，还是CGLIB代理，expose-proxy属性是为了解决有时候需要目标对象内部的自我调用无法实现切面的增强。最后调用registerComponentIfNecessary注册组建。 然后回到AspectjAutoProxyBeanDefinitionParse中调用extendBeanDefinition方法。这些执行之后spring容器中（getRegistry(),DefautListableBeanFactory）的beanDefinitionMap中会有key为org.springframework.aop.config.internalAutoProxyCreator，value为Root bean: class [org.springframework.aop.aspectj.annotation.AnnotationAwareAspectJAutoProxyCreator]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null的beanDefinition信息。 Aop注解内容的加载，代理的生成初始化入口为：上面说到AOP的核心逻辑是在AnnotationAwareAspectJAutoProxyCreator类里面实现，该类实现了BeanPostProcessor接口，这就意味着，spring加载实例前会调用postProcessBeforeInstantiation以及postProcessAfterInitialization方法，对于Aop的逻辑也是由此开始的，该方法的实现在：AbstractAutoProxyCreator中，初始化之前123456789101112131415161718192021222324252627282930@Overridepublic Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; Object cacheKey = getCacheKey(beanClass, beanName); if (beanName == null || !this.targetSourcedBeans.contains(beanName)) &#123; if (this.advisedBeans.containsKey(cacheKey)) &#123; return null; &#125; if (isInfrastructureClass(beanClass) || shouldSkip(beanClass, beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return null; &#125; &#125; // Create proxy here if we have a custom TargetSource. // Suppresses unnecessary default instantiation of the target bean: // The TargetSource will handle target instances in a custom fashion. if (beanName != null) &#123; TargetSource targetSource = getCustomTargetSource(beanClass, beanName); if (targetSource != null) &#123; this.targetSourcedBeans.add(beanName); Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(beanClass, beanName, targetSource); Object proxy = createProxy(beanClass, beanName, specificInterceptors, targetSource); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; &#125; return null;&#125; 初始化之前主要是从所有的bean中找到用户定义的aspect对应的bean。暂时还不是特别清楚。初始化之后：12345678910@Overridepublic Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (!this.earlyProxyReferences.contains(cacheKey)) &#123; return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean;&#125; 每个 bean实例化之前都会进过该方法，然后接下来调用wrapIfNecessary方法，该方法的重点在1Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); 这个方法会通过findCandidateAdvisors获取所有类型为Advisor的bean。然后通过findAdvisorsThatCanApply该方法获取对当前bean有效的Advisor，然后排序返回。最后最重要的来了，创建代理：1Object proxy = createProxy(bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); 该方法比较简单，设置一些基础的东西，属性，创建代理。先创建代理工厂proxyFactory，然后获取当前bean 的增强器advisors，然后使用defaultAopProxyFactory创建代理，创建代理的时候，根据是否制定了特定方式，选择创建JdkDynamicAopProxy或者ObjenesisCglibAopProxy。创建操作结束，接下来实例化也是对这个代理的实例化。 Aop动态代理执行JdkDynamicAopProxy则会调用内部的invoke方法，ObjenesisCglibAopProxy则会调用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public Object invoke(Object proxy, Method method, Object[] args) throwsThrowable &#123; MethodInvocation invocation = null; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Class targetClass = null; Object target = null; try &#123; //eqauls()方法，具目标对象未实现此方法 if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method))&#123; return (equals(args[0])? Boolean.TRUE : Boolean.FALSE); &#125; //hashCode()方法，具目标对象未实现此方法 if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method))&#123; return newInteger(hashCode()); &#125; //Advised接口或者其父接口中定义的方法,直接反射调用,不应用通知 if (!this.advised.opaque &amp;&amp;method.getDeclaringClass().isInterface() &amp;&amp;method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; // Service invocations onProxyConfig with the proxy config... return AopUtils.invokeJoinpointUsingReflection(this.advised,method, args); &#125; Object retVal = null; if (this.advised.exposeProxy) &#123; // Make invocation available ifnecessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; //获得目标对象的类 target = targetSource.getTarget(); if (target != null) &#123; targetClass = target.getClass(); &#125; //获取可以应用到此方法上的Interceptor列表 List chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method,targetClass); //如果没有可以应用到此方法的通知(Interceptor)，此直接反射调用 method.invoke(target, args) if (chain.isEmpty()) &#123; retVal = AopUtils.invokeJoinpointUsingReflection(target,method, args); &#125; else &#123; //创建MethodInvocation invocation = newReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); retVal = invocation.proceed(); &#125; // Massage return value if necessary. if (retVal != null &amp;&amp; retVal == target &amp;&amp;method.getReturnType().isInstance(proxy) &amp;&amp;!RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; // Special case: it returned&quot;this&quot; and the return type of the method // is type-compatible. Notethat we can&apos;t help if the target sets // a reference to itself inanother returned object. retVal = proxy; &#125; return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; // Must have come fromTargetSource. targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125;","categories":[],"tags":[]},{"title":"Curator之LeaderLatch使用","slug":"Curator之LeaderLatch使用","date":"2017-08-30T08:33:53.000Z","updated":"2017-08-31T07:24:58.000Z","comments":true,"path":"2017/08/30/Curator之LeaderLatch使用/","link":"","permalink":"http://www.merlin4io.com/2017/08/30/Curator之LeaderLatch使用/","excerpt":"背景简介Zookeeper在分布式系统中，常常被用于选主。在执行某个任务时，让所有的节点都知道有一个特别的，唯一的节点是任务的主节点，由主节点进行任务的执行，其他节点作为备用节点。通过这种热备方式，为分布式系统中任务执行的可控性，以及系统高可用性。作为zookeeper的高级api封装库curator选主算法主要有以下两个：Leader Latch和Leader Election今天简单的介绍一下Leader Latch。LeaderLatch的方式，就是以一种抢占的方式来决定选主。比较简单粗暴，逻辑相对简单。类似非公平锁的抢占，所以，多节点是一个随机产生主节点的过程。基本就是，谁抢到就算谁的。多个参与者（如：逻辑节点；某个线程等），指定在一个分组之下，每个分组内进行主节点抢占。","text":"背景简介Zookeeper在分布式系统中，常常被用于选主。在执行某个任务时，让所有的节点都知道有一个特别的，唯一的节点是任务的主节点，由主节点进行任务的执行，其他节点作为备用节点。通过这种热备方式，为分布式系统中任务执行的可控性，以及系统高可用性。作为zookeeper的高级api封装库curator选主算法主要有以下两个：Leader Latch和Leader Election今天简单的介绍一下Leader Latch。LeaderLatch的方式，就是以一种抢占的方式来决定选主。比较简单粗暴，逻辑相对简单。类似非公平锁的抢占，所以，多节点是一个随机产生主节点的过程。基本就是，谁抢到就算谁的。多个参与者（如：逻辑节点；某个线程等），指定在一个分组之下，每个分组内进行主节点抢占。 LeaderLatch创建它的构造函数如下： 12public LeaderLatch(CuratorFramework client, String latchPath)public LeaderLatch(CuratorFramework client, String latchPath, String id) 参数说明：client : zk客户端链接latchPath : 分组路径（zk中的path）id : 参与者ID LeaderLatch启动LeaderLatch创建之后，需要调用对应的start方法才能开始选主。1leaderLatch.start(); 一旦启动， LeaderLatch会和其它使用相同latch path的其它LeaderLatch交涉，然后随机的选择其中一个作为leader。 你可以随时查看一个给定的实例是否是leader，来检测当前参与者是否选主成功。这个方法是非阻塞的（立即返回），其结果只代表调用时的选主结果。所以，可以轮询此方法，或者当执行完本地逻辑后，需要执行分布式任务前检查此方法。 1public boolean hasLeadership() LeaderLatch的await方法和countDownlatch的await方法类似，也是阻塞的。 12public void await() throws InterruptedException,EOFExceptionpublic boolean await(long timeout,TimeUnit unit) throws InterruptedException LeaderLatch监听器但是一般在start之前会先添加对应的监听器LeaderLatchListener，然后配合await方法使用，LeaderLatchListener中的方法： 12public void isLeader();public void notLeader(); 然后在isLeader方法中执行对应的逻辑，notLeader中处理一些需要处理的内容。 LeaderLatch异常处理：在实际使用中，必须考虑链接问题引起的主身份丢失问题。 例如：当hasLeadership()返回true，之后链接出问题。 强烈建议：使用LeaderLatch时为其添加一个ConnectionStateListenerLeaderLatch实例会添加一个ConnectionStateListener来监听当前zk链接。 如果，链接不可用（SUSPENDED）则LeaderLatch会认为自己不在是主，等到链接恢复可用时，才可继续。 如果，链接断开（LOST），则LeaderLatch会认为自己不在是主，等到链接重新建立后，删除之前的参与者信息，然后重新参与选主。 参考文档：[Curator] Leader Latch 的使用与分析跟着实例学习ZooKeeper的用法： Leader选举","categories":[],"tags":[]},{"title":"亿级流量大纲摘要","slug":"亿级流量目录","date":"2017-08-28T02:36:15.000Z","updated":"2017-08-31T07:27:04.000Z","comments":true,"path":"2017/08/28/亿级流量目录/","link":"","permalink":"http://www.merlin4io.com/2017/08/28/亿级流量目录/","excerpt":"交易型系统的一些基本原则 高并发 无状态：代码无状态，可以快速回滚，扩容。 拆分：服务垂直拆分 服务化 消息队列（异步处理），大流量缓冲，最后数据校对（防止消息丢失） 数据异构（分库分表之后，数据异构，数据聚合之后异构，可以通过es实现） 并行化（统一请求的不同资源获取，可以并行处理，提高效率） 缓存 浏览器缓存 app客户端缓存 cdn缓存 接入层缓存 应用层缓存 分布式缓存","text":"交易型系统的一些基本原则 高并发 无状态：代码无状态，可以快速回滚，扩容。 拆分：服务垂直拆分 服务化 消息队列（异步处理），大流量缓冲，最后数据校对（防止消息丢失） 数据异构（分库分表之后，数据异构，数据聚合之后异构，可以通过es实现） 并行化（统一请求的不同资源获取，可以并行处理，提高效率） 缓存 浏览器缓存 app客户端缓存 cdn缓存 接入层缓存 应用层缓存 分布式缓存 高可用 降级：服务降级，不重要的服务可以做降级处理，数据读取降级，控制只读本地缓存了，只读分布式缓存等。 限流：防止恶意请求流量，恶意攻击，或者防治流量超过系统峰值，首先要区分出这些请求，能够区分出来的，比如说，这么分流量只请求缓存，ip屏蔽等。 切流量 dns切机房 lvs/haproxy切换故障的nginx接入层 nginx切换应用层 可回滚：代码可回滚，部署可回滚，数据可回滚，静态资源可回滚等 隔离：超时隔离等， 业务设计原则 防重设计：防止重复支付，重复扣库存。 幂等设计：防止消息重复，接口重复调用。 流程可定义： 状态和状态机： 后台系统操作可反馈：设置之后可以预览 后台系统审批化：一些重要操作要审批，记录操作日志 文档和注释：避免只能看代码了解，文档库：设计架构，设计思想，数据字典，业务流程，现有问题。 备份：代码和人员，代码有仓库管理，人员要有备份，防止突然离职，请假，不可替代。 高可用之负载均衡与反向代理 负载均衡的原理：待补充 upstring配置（负载均衡的配置） 负载均衡算法：轮训，加权轮训，随机，加权随机，原地址hash（一致性hash），最小链接法 失败重试，超时重试 健康检查 tcp心跳检查 http心跳检查 应用健康检查（定时访问应用的api，检查是否畅通） 长链接 http反向代理 http动态负载均衡 高可用之隔离术 线程隔离：不同事情的线程池，使用不同的，重要的业务，单独用，不重要的可以共用一个 进程隔离：应用拆分，不同功能部署不同地方 集群隔离：服务分组，集群中的某些服务单独存在调用链，比如说，秒杀调用链和其他的调用链可以分组，隔离。 机房隔离：不进行跨机房条用， 读写隔离：主从数据库 动静隔离： 爬虫隔离：根据请求头，引流到固定地址 热点隔离： 资源隔离：使用hystrix实现隔离 高可用之限流 令牌桶算法：固定速率产生令牌到令牌桶中，令牌桶满了，就丢弃或者拒绝，每个请求过来的时候去令牌桶中获取令牌（一次可以获取多个），获取不到，被限流（丢弃或者在缓冲区等待），获取到了，继续往下走，可以允许突发流量。 漏桶算法：每个请求都先到漏桶中，固定速率从漏桶中获取请求，往下走，如果漏桶满的时候，请求方不进去，直接丢弃。 应用级限流:限流总并发/连接/请求数 分布式限流 redis+lua实现。 nginx+lua实现。 高可用之降级 降级开关 读服务降级 写服务降级 多级降价 配置中心 hystrix实现降级。 高可用之重试与重试 web容器超时 中间件客户端超时 数据库客户端超时 nosql客户端超时 业务超时 前段请求超时 高可用之回滚 事务回滚 代码库回滚 部署版本回滚 数据版本回滚 静态资源回滚 高可用之压测与预案 高并发之应用级缓存缓存命中率（从缓存查/总查询次数） 缓存回收策略 基于空间（大于10兆） 基于容量（大于1000条） 基于时间 存活期（创建5min后过期） 空闲期（连续5min没有使用过期） 基于java对象 软引用 弱引用 回收算法 先入先出fifo 最近最少使用lru 最不常用 lfu java缓存模型 堆缓存 堆外缓存 磁盘缓存 分布式缓存 多级缓存 多级缓存api封装 NULLcache。 强制使用最新数据 失败统计 延迟报警","categories":[],"tags":[]},{"title":"Mybaties主从数据库扩展","slug":"Mybaties主从数据库扩展","date":"2017-06-27T03:42:07.000Z","updated":"2018-07-26T15:59:44.000Z","comments":true,"path":"2017/06/27/Mybaties主从数据库扩展/","link":"","permalink":"http://www.merlin4io.com/2017/06/27/Mybaties主从数据库扩展/","excerpt":"mybaties，扩展主从读写分离。 首先扩展DataSource : RoutingDataSource extends AbstractDataSource 设置主从数据库DataSource。然后重写getConnection方法，根据条件获取具体使用哪一个数据源，是主库master，还是从库（多个从库可以考虑从库的负载策略），比如说如果是有事务就需要选择主库，如果没有从库就选择主库，等等。这个地方的是否开启事务，以及使用者自己定义的主从库信息通过线程变量来获取。","text":"mybaties，扩展主从读写分离。 首先扩展DataSource : RoutingDataSource extends AbstractDataSource 设置主从数据库DataSource。然后重写getConnection方法，根据条件获取具体使用哪一个数据源，是主库master，还是从库（多个从库可以考虑从库的负载策略），比如说如果是有事务就需要选择主库，如果没有从库就选择主库，等等。这个地方的是否开启事务，以及使用者自己定义的主从库信息通过线程变量来获取。DefaultSqlSessionTemplate实现SqlSession接口的查询方法并且声明实现getSqlSession()方法，生成sqlSession 代理的时候，跳用getSqlSession()获取，该方法默认实现为：SqlSessionUtils.getSqlSession(sqlSessionFactory, executorType, exceptionTranslator); RoutingSqlSessionTemplate继承DefaultSqlSessionTemplate，覆盖getSqlSession()方法。 RoutingSqlSessionWrapper实现sqlSession接口，内部引用一个RoutingSqlSessionTemplate,所有的实现都是通过RoutingSqlSessionTemplate来实现，只是在外面包装了一下，在实际操作的前后，添加了把使用者使用的数据源，和这一次的数据哭操作行为放到线程变量中，方便dataSource调用getConnection的时候做一些判断。调用结束后，清除线程变量。 RoutingDataSourceTransactionManager extends DataSourceTransactionManager 扩展DataSourceTransactionManager做事务管理。 配置的时候，配置mybaties的sqlSessionFactory中的数据源唯封装过的RoutingDataSource,RoutingDataSource中配置maser数据源和slave数据源。在commonDao使用工厂bean初始化的时候，判断，数据源是否为扩展的RoutingDataSource，以及是否没有slave，如果没有，就使用SqlSessionTemplate创建sqlSession，如果有主从，使用RoutingSqlSessionTemplate创建SqlSession. 然后在使用者使用的时候，设置对应的Mapper，对应的sql，对应的数据源（master，slave）。然后包装sqlSession，如果sqlSession是RoutingSqlSessionTemplate则使用RoutingSqlSessionWrapper替代，然后调用具体的方法。这两部，可以有抽象的，SimpleSqlSession，SimpleMapper 来做一些事情。","categories":[],"tags":[]},{"title":"简单谈谈对HashMap的理解","slug":"简单谈谈对HashMap的理解","date":"2017-05-15T14:39:26.000Z","updated":"2018-07-24T14:57:07.000Z","comments":true,"path":"2017/05/15/简单谈谈对HashMap的理解/","link":"","permalink":"http://www.merlin4io.com/2017/05/15/简单谈谈对HashMap的理解/","excerpt":"HashMap的原理HashMap的原理是Hash。使用put(key,value)的方式存储数据，使用get(key)获取数据。put的时候对key做hash算法，决定放到那个buket里面，map的底层实现是一个entry链表的数组。put的时候如果发生hash冲突，会对比key的equals方法，返回true，覆盖，返回false，则存放到entry链表中。当元素的数量大于初始值的0.75时，会扩充为原来的两倍大小。扩充会有线程安全问题，扩充之后，会把原来的元素重新hash存储。hashMap的大小最好时2的幂次方，这样的好处是，扩容方便，直接移位即可，另外存放获取的时候效率会高一点，因为每个key做hash之后要和map的大小做&amp;确定key存储在哪一个buket上面。","text":"HashMap的原理HashMap的原理是Hash。使用put(key,value)的方式存储数据，使用get(key)获取数据。put的时候对key做hash算法，决定放到那个buket里面，map的底层实现是一个entry链表的数组。put的时候如果发生hash冲突，会对比key的equals方法，返回true，覆盖，返回false，则存放到entry链表中。当元素的数量大于初始值的0.75时，会扩充为原来的两倍大小。扩充会有线程安全问题，扩充之后，会把原来的元素重新hash存储。hashMap的大小最好时2的幂次方，这样的好处是，扩容方便，直接移位即可，另外存放获取的时候效率会高一点，因为每个key做hash之后要和map的大小做&amp;确定key存储在哪一个buket上面。 hash算法首先算得key得hashcode值，然后跟数组的长度-1做一次“与”运算（&amp;）。看上去很简单，其实比较有玄机。比如数组的长度是2的4次方，那么hashcode就会和2的4次方-1做“与”运算。很多人都有这个疑问，为什么hashmap的数组初始化大小都是2的次方大小时，hashmap的效率最高，我以2的4次方举例，来解释一下为什么数组大小为2的幂时hashmap访问的性能最高。 看下图，左边两组是数组长度为16（2的4次方），右边两组是数组长度为15。两组的hashcode均为8和9，但是很明显，当它们和1110“与”的时候，产生了相同的结果，也就是说它们会定位到数组中的同一个位置上去，这就产生了碰撞，8和9会被放到同一个链表上，那么查询的时候就需要遍历这个链表，得到8或者9，这样就降低了查询的效率。同时，我们也可以发现，当数组长度为15的时候，hashcode的值会与14（1110）进行“与”，那么最后一位永远是0，而0001，0011，0101，1001，1011，0111，1101这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率，减慢了查询的效率！ 所以说，当数组长度为2的n次幂的时候，不同的key算得得index相同的几率较小，那么数据在数组上分布就比较均匀，也就是说碰撞的几率小，相对的，查询的时候就不用遍历某个位置上的链表，这样查询效率也就较高了。 说到这里，我们再回头看一下hashmap中默认的数组大小是多少，查看源代码可以得知是16，为什么是16，而不是15，也不是20呢，看到上面annegu的解释之后我们就清楚了吧，显然是因为16是2的整数次幂的原因，在小数据量的情况下16比15和20更能减少key之间的碰撞，而加快查询的效率。 所以，在存储大容量数据的时候，最好预先指定hashmap的size为2的整数次幂次方。就算不指定的话，也会以大于且最接近指定值大小的2次幂来初始化的，代码如下(HashMap的构造方法中)： 1234// Find a power of 2 &gt;= initialCapacity int capacity = 1; while (capacity &lt; initialCapacity) capacity &lt;&lt;= 1; HashMap的resize当hashmap中的元素越来越多的时候，碰撞的几率也就越来越高（因为数组的长度是固定的），所以为了提高查询的效率，就要对hashmap的数组进行扩容，数组扩容这个操作也会出现在ArrayList中，所以这是一个通用的操作，很多人对它的性能表示过怀疑，不过想想我们的“均摊”原理，就释然了，而在hashmap数组扩容之后，最消耗性能的点就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是resize。 那么hashmap什么时候进行扩容呢？当hashmap中的元素个数超过数组大小x loadFactor时，就会进行数组扩容，loadFactor的默认值为0.75，也就是说，默认情况下，数组大小为16，那么当hashmap中元素个数超过160.75=12的时候，就把数组的大小扩展为216=32，即扩大一倍，然后重新计算每个元素在数组中的位置，而这是一个非常消耗性能的操作，所以如果我们已经预知hashmap中元素的个数，那么预设元素的个数能够有效的提高hashmap的性能。比如说，我们有1000个元素new HashMap(1000), 但是理论上来讲new HashMap(1024)更合适，不过上面annegu已经说过，即使是1000，hashmap也自动会将其设置为1024。 但是new HashMap(1024)还不是更合适的，因为0.751000 &lt; 1000, 也就是说为了让0.75 size &gt; 1000, 我们必须这样new HashMap(2048)才最合适，既考虑了&amp;的问题，也避免了resize的问题。 原文链接：深入理解HashMap","categories":[],"tags":[]},{"title":"Kafka到logstash到elasticsearch到kinana","slug":"Kafka到logstash到elasticsearch到kinana","date":"2017-04-12T05:43:32.000Z","updated":"2017-08-31T07:27:13.000Z","comments":true,"path":"2017/04/12/Kafka到logstash到elasticsearch到kinana/","link":"","permalink":"http://www.merlin4io.com/2017/04/12/Kafka到logstash到elasticsearch到kinana/","excerpt":"下载地址zookeeper: https://zookeeper.apache.org/releases.html 最新版走起。 文档地址： https://zookeeper.apache.org/doc/r3.5.2-alpha/zookeeperStarted.html 够详细了，创建conf文件，启动，命令行连接。 kafka：http://kafka.apache.org/downloads 最新版的搞起. 文档地址：http://kafka.apache.org/quickstart 一步一步往前走。 elasticsearch :https://www.elastic.co/cn/downloads/elasticsearch 最新版然后启动命令什么的都有。 详细文档地址：https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html kibana:https://www.elastic.co/cn/downloads/kibana 详细文档地址： https://www.elastic.co/guide/en/kibana/current/getting-started.html logstash:https://www.elastic.co/cn/downloads/logstash 详细文档地址：https://www.elastic.co/guide/en/logstash/current/getting-started-with-logstash.html","text":"下载地址zookeeper: https://zookeeper.apache.org/releases.html 最新版走起。 文档地址： https://zookeeper.apache.org/doc/r3.5.2-alpha/zookeeperStarted.html 够详细了，创建conf文件，启动，命令行连接。 kafka：http://kafka.apache.org/downloads 最新版的搞起. 文档地址：http://kafka.apache.org/quickstart 一步一步往前走。 elasticsearch :https://www.elastic.co/cn/downloads/elasticsearch 最新版然后启动命令什么的都有。 详细文档地址：https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html kibana:https://www.elastic.co/cn/downloads/kibana 详细文档地址： https://www.elastic.co/guide/en/kibana/current/getting-started.html logstash:https://www.elastic.co/cn/downloads/logstash 详细文档地址：https://www.elastic.co/guide/en/logstash/current/getting-started-with-logstash.html 注意事项其实所有的文档，上面都有的，每个工具如何配置，启动都有了，有些需要自己创建配置文件，有些需要修改一些地址。 首先zookeeper的配置文件，需要自己新建，copy一个zoo_sample.cfg重命名为zoo.cfg可以制定启动的端口号，数据的存储地址。然后启动，可以通过zkClient自己连接之后测试。sh zkClient.sh -server localhost:2181. kafka的配置：server.properties中配置zookeeper.connect=localhost:2181；zookeeper.properties中配置端口clientPort。然后可以根据文档提示，启动服务，打开生产者窗口，打开消费者窗口，可以自己玩了。 elasticsearch的配置，可以使用默认，配置内容在elasticsearch.yml，可以修改cluster.name。这个地方有个注意的东西，如果自己安装了x-pack,会启用安全检测，es打开的时候需要输入用户名密码，用户名：”elastic”密码：”changeme”。后面kiban配置的时候需要在kibana.yml中配置elasticsearch.username: “elastic”elasticsearch.password: “changeme” 以及elasticsearch.url: “http://localhost:9200“elasticsearch启动之后可以 http://localhost:9200/?pretty打开验证。 kibana配置之后打开http://localhost:5601/验证。 logstash的配置:logstash配置文件需要自己新建，内容： 12345678910111213141516input &#123; kafka&#123; bootstrap_servers =&gt; &quot;localhost:9092&quot; group_id =&gt; &quot;logstash&quot; topics =&gt; [&quot;xiazhou_test&quot;] consumer_threads =&gt; 5 decorate_events =&gt; true &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;127.0.0.1:9200&quot;] user =&gt; elastic password =&gt;changeme &#125; &#125; 其中kafka中需要制定topics，topics是个数组，按照kafka创建的topic填写即可。bootstrap_servers为kafka的地址，可以是集群，老的方式可以配置zk地址，新版本现在不支持。这些配置之后，可以 通过。bin/logstash -f config/logstash_simple.conf来启动，然后可以在命令行发消息到topic中，然后会到elasticsearch中。 打开kibana，配置Configure an index pattern，然后就可以看到具体的内容了。","categories":[],"tags":[]},{"title":"性能优化之字符串操作","slug":"性能优化之字符串操作","date":"2017-03-13T14:02:54.000Z","updated":"2017-04-27T08:13:11.000Z","comments":true,"path":"2017/03/13/性能优化之字符串操作/","link":"","permalink":"http://www.merlin4io.com/2017/03/13/性能优化之字符串操作/","excerpt":"","text":"字符串的三个优化： 不可变 常量池 final类 不可变解决了线程安全问题，不用考虑线程安全问题。常量池，把经常食用的字符串放在常量池中，减少不断的创建，final类，安全。String的实现为，一个char[]数组，一个offset偏移量，一个lentgh长度。 使用String需要注意的几个问题 subString(int start),subString(int start ,int end)，两个方法最终都会使用字符串的一个构造方法，new Strign(int offset,int length,char[] value),所以每次subString都会生成新的字符串，而且调用的时候是，new String(offset+start,end-start,this.value),这样就会每次子串都含有一个原来char[]数组的引用，导致char[]数组不能被垃圾回收器回收，如果char[]数组很大，操作次数达到一定程度就会导致内存泄漏。这也是用空间换取时间的方法。可以使用subString之后在用当前字符串new一个出来，这样原来char[]数组的饮用就会被垃圾回收回收掉。 split(String reg),根据某个字符分割，可以支持正则表达式，但是这个效率很低，可以选择使用StringTokenizer来分隔，效率会高一点，挥着自己实现，不断的调用indexOf和subString即可，只要注意处理好内存就可以了。因为indexOf，和subString都是很高效的。同样charAt也是很高效的。 字符串的拼接，如果是常量则虽然是string+string,但是编译之后就会合并成一个字符串，如果不是常量，string+变量，编译器会转化成stringBuilder的apend，但是有的时候，编译器并不是智能的，转化过程中，new StringBuilder().append()。如果循环构建就会新建很多的StringBuilder。所以最好自己使用StringBuilder拼接，类似的有StringBuffer,StringBuffer是线程安全的。其他的和StringBuilder一样。 startWith，endWith比较慢，可以使用charAt来代理。如果明确知道参数的话。 扩展阅读： Java中关于String类型的10个问题","categories":[],"tags":[]},{"title":"消息中间件微扩展","slug":"消息中间件微扩展","date":"2017-02-03T09:43:10.000Z","updated":"2017-08-31T07:27:38.000Z","comments":true,"path":"2017/02/03/消息中间件微扩展/","link":"","permalink":"http://www.merlin4io.com/2017/02/03/消息中间件微扩展/","excerpt":"正常情况下提供者： 构建发送消息template，需要一个mq的连接工厂类，连接工厂类，获取到之后，指定发送的队列的名字。 消费者： 一个队列的消费容器中制定对应的mq的连接工厂类，接受消息的队列信息，接收到消息之后的监听器，默认并发的消费数量。 中间件之后：ActiveMQ中，topic只有在持久订阅（durablesubscription）下是持久化的。存在持久订阅时，每个持久订阅者，都相当于一个持久化的queue的客户端，它会收取所有消息。这种情况下存在两个问题：","text":"正常情况下提供者： 构建发送消息template，需要一个mq的连接工厂类，连接工厂类，获取到之后，指定发送的队列的名字。 消费者： 一个队列的消费容器中制定对应的mq的连接工厂类，接受消息的队列信息，接收到消息之后的监听器，默认并发的消费数量。 中间件之后：ActiveMQ中，topic只有在持久订阅（durablesubscription）下是持久化的。存在持久订阅时，每个持久订阅者，都相当于一个持久化的queue的客户端，它会收取所有消息。这种情况下存在两个问题： 同一应用内consumer端负载均衡的问题：同一个应用上的一个持久订阅不能使用多个consumer来共同承担消息处理功能。因为每个都会获取所有消息。queue模式可以解决这个问题，broker端又不能将消息发送到多个应用端。所以，既要发布订阅，又要让消费者分组，这个功能jms规范本身是没有的。 同一应用内consumer端failover的问题：由于只能使用单个的持久订阅者，如果这个订阅者出错，则应用就无法处理消息了，系统的健壮性不高。 为了解决这两个问题，ActiveMQ中实现了虚拟Topic的功能。使用起来非常简单。对于消息发布者来说，就是一个正常的Topic，名称以VirtualTopic.开头。例如VirtualTopic.TEST。 对于消息接收端来说，是个队列，不同应用里使用不同的前缀作为队列的名称，即可表明自己的身份即可实现消费端应用分组。例如Consumer.A.VirtualTopic.TEST，说明它是名称为A的消费端，同理Consumer.B.VirtualTopic.TEST说明是一个名称为B的客户端。可以在同一个应用里使用多个consumer消费此queue，则可以实现上面两个功能。又因为不同应用使用的queue名称不同（前缀不同），所以不同的应用中都可以接收到全部的消息。每个客户端相当于一个持久订阅者，而且这个客户端可以使用多个消费者共同来承担消费任务。 发送方如果是TOPIC消息,会向TOPIC的VirtualTopic.xiazhou 发送消息，可以在后台的TOPIC页面中看到 接收者启动的时候会生成一个Consumer.wechat.VirtualTopic.xiazhou 中间的wechat是消费者应用 MQ做的当收到 VirtualTopic.xiazhou 消息，先去找有多少Consumer.XXXXX.VirtualTopic.xiazhou的队列把这条消息拷贝N份，放到每个队列里面 接收者消费自己注册的队列里面的数据，如果有4台，随机分发，保证了集群4台收一份数据 提供者： 使用方发送topic消息到newOrder主题。 提供者定一个事件，事件中指定了主题名字，然后通过messageEventFactory的publishEvent方法，发布事件。 发布事件中，根据主题名字加上分区信息，构建出来一个新的主题名字。然后获取对应的mq的连接工厂， 使用连接工厂获得连接，根据连接获取会话，根据会话构建一个提供者，提供者提供的事主题消息，然后使用提供者发送主题消息。 提供者封装后发送消息到VirtualTopic.newOrder. 消费者： 使用方监听newOrder主题。 一开始获取到所有的自定义的消费者监听器，消费者监听器中指定了可以并发消费的数量，指定了消费的分组方式，默认消费分组为系统名称。 获取所有的消费者自定义监听器，遍历，然后按照主题名字和消费分组组装成一个key，把key和对应的listener放到一个map中。然后使用连接工厂获取一个mq连接，然后启动连接。遍历前面的map，根据key获取到对应的listener，根据连接，获取一个session会话。 然后根据消费分组，主题名称，分区信息，创建一个队列，然后回话根据队列构建出一个消费者，然后设置消费者对应的监听器，这个监听器事动态构建的，监听这个队列，当有消息到这个队列的时候，出发这个动态的监听器，动态的监听器会调用我们自定义的监听器的对应处理消息方法。 封装后每个消费者都会注册监听器到Consumer.appName.VirtualTopic.xiazhou队列。有消息发送到VirtualTopic.newOrder主题的，监听在Consumer.*.VirtualTopic.xiazhou队列的消费者都会受到消息。 依赖点：消费者需要先发布，创建好对应的消费队列，然后发送主题消息之后才会分到对应的消费队列中去,也就是发送主题消息之前所有的消费者队列需要已经创建。不然会有消息丢失问题。 扩展点：可以对消息添加版本的概念，然后不同的版本消息会发送到与版本相关的主题，然后队列页时不同的版本，这样解决发布依赖问题，如果发布的过程中想要测试，这样会很方便。","categories":[],"tags":[]},{"title":"大型网站系统与java中间件实践","slug":"大型网站系统与java中间件实践","date":"2017-01-04T14:34:04.000Z","updated":"2017-01-06T14:50:50.000Z","comments":true,"path":"2017/01/04/大型网站系统与java中间件实践/","link":"","permalink":"http://www.merlin4io.com/2017/01/04/大型网站系统与java中间件实践/","excerpt":"","text":"什么是分布式系统各个组件分布在不同的网络计算机上，组件之间仅仅荣哟消息传递来通信并协调行动。 大型网站发展： 单机 ，应用和数据库放在一起。 单机+缓存，应用和数据库之间添加一层缓存。 应用和数据库拆分，缓存在应用层。 数据库读写分离 应用部署集群， 分布式缓存，集中缓存 搜索引擎(lucene,solr)，分布式文件系统。 应用垂直拆分(分压，解耦)， 数据库垂直拆分(分压，解耦) 服务化(解耦去重复)通信rpc 解耦消息中间件(吞吐量) 数据库水平拆分，分库分表。 分布式系统的意义在于： 升级单机处理能力的性价比越来越低 单机处理能力存在瓶颈 出于稳定性和可用性的考虑 分布式系统会遇到哪些问题？ 全局时钟 全局sequence 全局事务 数据个维度查询 分布式锁 如何解决这些问题？服务框架远程服务框架，现在成型的多个，可以选择开源的来用。消费者：接口调用–&gt;寻址路由–&gt;编码–&gt;通信提供者： –&gt;通信– &gt;解码–&gt;实例定位–&gt;服务调用. 数据库访问层分库分表中间件，使用方便无感知，解决分库分表之后数据的查询，分库分表之后的sequence 消息中间件消息中间间与消息丢失。 配置中心灵活配置各种参数","categories":[],"tags":[]},{"title":"Uml随手记","slug":"Uml随手记","date":"2016-11-11T01:45:35.000Z","updated":"2017-08-31T03:39:53.000Z","comments":true,"path":"2016/11/11/Uml随手记/","link":"","permalink":"http://www.merlin4io.com/2016/11/11/Uml随手记/","excerpt":"","text":"依赖：通过局部变量，或者方法参数，虚线箭头:A——&gt;B：表示A依赖B； 关联：通过成员变量实现，涉及的两个类在同一个层次上，实线箭头:A——&gt;B,A中有一个B属性，可以指明A中有多少个B。 聚合：通过成员变量实现，涉及的两个类一个表示整体，一个表示部分。整体和部分可以单独存在 虚心棱形 加箭头 合成：更强的组合关系，部分离开整体不能单独存在，实心菱形加箭头。 泛化：三角+实线 实现：三角+虚线。","categories":[],"tags":[]},{"title":"Java之RMI与zookeeper","slug":"Java之RMI与zookeeper","date":"2016-11-10T07:49:10.000Z","updated":"2017-08-31T07:41:36.000Z","comments":true,"path":"2016/11/10/Java之RMI与zookeeper/","link":"","permalink":"http://www.merlin4io.com/2016/11/10/Java之RMI与zookeeper/","excerpt":"RMI简介通过RMI（Remote Method Invocation，远程方法调用）可以实现跨虚拟机调用，A项目和B项目分别在不同的虚拟机上工作，如果要实现A项目可以访问B项目，可以使用RMI来实现。也可以使用其他方式，比如http等，但是RMI的方式要快很多。在分布式系统中，我们更需要这种技术，一个项目提供服务，另一个项目作为消费者来使用提供者提供的服务，充分体现组件之间的弱耦合，系统架构更容易扩展。先简单的说说RMI怎么用吧。 发布RMI接口发布RMI接口需要做什么？ 定义一个 RMI 接口 编写 RMI 接口的实现类 通过 JNDI 发布 RMI 服务","text":"RMI简介通过RMI（Remote Method Invocation，远程方法调用）可以实现跨虚拟机调用，A项目和B项目分别在不同的虚拟机上工作，如果要实现A项目可以访问B项目，可以使用RMI来实现。也可以使用其他方式，比如http等，但是RMI的方式要快很多。在分布式系统中，我们更需要这种技术，一个项目提供服务，另一个项目作为消费者来使用提供者提供的服务，充分体现组件之间的弱耦合，系统架构更容易扩展。先简单的说说RMI怎么用吧。 发布RMI接口发布RMI接口需要做什么？ 定义一个 RMI 接口 编写 RMI 接口的实现类 通过 JNDI 发布 RMI 服务 定义RMI接口首先定一个接口继承Remote类。定义方法，方法要抛出RemoteException。 eg: package com.cydeer.demo.rmi.api; import java.rmi.Remote; import java.rmi.RemoteException; /** * Created by zhangsong on 16/8/11. */ public interface HelloWordService extends Remote { String sayHello(String name) throws RemoteException; } 对应的实现类然后写接口具体的实现，实现要继承UnicastRemoteObject，然后实现刚才定义的接口。此外，必须提供一个构造器，并且构造器必须抛出 java.rmi.RemoteException 异常。 eg： package com.cydeer.demo.rmi.api; import java.rmi.RemoteException; import java.rmi.server.UnicastRemoteObject; /** * Created by zhangsong on 16/8/11. */ public class HelloWordServiceImpl extends UnicastRemoteObject implements HelloWordService { public HelloWordServiceImpl() throws RemoteException { } @Override public String sayHello(String name) throws RemoteException { System.out.println(&quot;hello &quot; + name); return name; } } 通过JNDI发布服务发布服务就像http请求一样，有对应的协议，有对应的ip，和对应的端口，以及要访问的资源，RMI的协议是rmi://，然后对应的ip就是发布服务的ip，对应的端口，默认是1099，可以自己设置，使用方式： HelloWordService helloWordService = new HelloWordServiceImpl(); int port = 9088; String url = &quot;rmi://localhost:&quot; + port + &quot;/helloWordService&quot;; LocateRegistry.createRegistry(port); Naming.rebind(url, new HelloWordServiceImpl()); 代码放到main方法里面就可以直接用了。LocateRegistry.createRegistry(port);通过jndi注册到注册表，Naming.rebind(url, new HelloWordServiceImpl());把对应的url，和对应实现类做一个绑定。","categories":[],"tags":[]},{"title":"多线程之concurrent包","slug":"多线程之concurrent包","date":"2016-11-10T07:46:14.000Z","updated":"2017-08-31T07:28:54.000Z","comments":true,"path":"2016/11/10/多线程之concurrent包/","link":"","permalink":"http://www.merlin4io.com/2016/11/10/多线程之concurrent包/","excerpt":"信号量（Semaphore）控制线程并发的数量。主要限制并发线程的数量，如果不限制并发线程的数量则CPU的资源会很快会被耗尽，每个线程执行的任务是相当缓慢，因为CPU要把时间片分配给不同的线程对象，而且上下文的切换也要耗时，最终导致系统运行效率降低，所以，控制并发线程的数量是必要的。","text":"信号量（Semaphore）控制线程并发的数量。主要限制并发线程的数量，如果不限制并发线程的数量则CPU的资源会很快会被耗尽，每个线程执行的任务是相当缓慢，因为CPU要把时间片分配给不同的线程对象，而且上下文的切换也要耗时，最终导致系统运行效率降低，所以，控制并发线程的数量是必要的。可以做线程同步之用，类似于synchroinzed,reentrantLock. 声明只能有一个线程同步反问的信号量： int permits = 1; Semaphore semaphore = new Semaphore(permits); 同步之前调用semaphore.acquire();同步结束之后调用semaphore.release();Semphore的构造函数参数permits代表同一时间内，最多允许多少个线程同时执行acquire()与release()之间的代码。 每次获取许可也可以指定获取多少个许可，acquire(permits);信号量的声明也可以声明称公平的和非公平的。 ExchangerExchanger可以使两个线程时间传输数据，他比使用wait，notify的生产者，消费者更方便，Exchanger.exchange(T result);具有阻塞性。如果没有其他线程取得数据就一直阻塞等待。 CountDownLatch是一个倒计数的锁存器，当计数减至0时触发特定的事件。先等待，等所有的参与者都调用了countDown(),之后继续执行。 声明一个总数为10的倒计数锁存器： CountDownLatch latch = new CountDownLatch(10); 进入阻塞状态： latch.await(); 当调用latch.countDown();达到10次的时候，就会开始执行await()下面的代码； CyclicBarrier一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。CyclicBarrier 支持一个可选的 Runnable 命令，在一组线程中的最后一个线程到达之后（但在释放所有线程之前），该命令只在每个屏障点运行一次。若在继续所有参与线程之前更新共享状态，此屏障操作 很有用。类似CountDownLatch，但这个是累加的，先到达的先等待，等到所有的参与者都到了之后所有的参与者都一起向下执行。 声明一个栅栏： CyclicBarrier barrier = new CycliBarrier(5); 或者 CyclicBarrier barrier = new CycliBarrier(5,new Runable(){ public void run(){ } }); 先到先等待： barrier.await(); 都到了就触发公共屏障点的Runable,然后继续往下面执行。 Phaser设置多屏障，动态添加计数。主要方法：new Phaser(parties);parties为计数的总数。arriveAndAwaitAdvance();计数满足的时候会放行，也可以在计数满足之后执行onAdvance方法然后放行。可以使用arriverAndDeregister(),可以使parites减一。register()方法可以增加parties的数量。 可以动态添加参与者。","categories":[],"tags":[]},{"title":"多线程之线程池","slug":"多线程之线程池","date":"2016-11-10T07:45:21.000Z","updated":"2017-08-31T07:28:49.000Z","comments":true,"path":"2016/11/10/多线程之线程池/","link":"","permalink":"http://www.merlin4io.com/2016/11/10/多线程之线程池/","excerpt":"接口Executor: void execute(Runnable command);提交任务。 ExecutorService，继承Executor: void shutdown();拒绝接受新任务，会把队列里面的任务也执行掉，如果任务中有中断判断是可以中断的，否则执行完。 List shutdownNow();拒绝接受新任务，返回没有执行的任务列表，如果任务中有中断判断，是可以中断的，否则就执行完。 Future submit(Callable); 提交一个有返回值的任务，submit的任务不能够被remove。 List","text":"接口Executor: void execute(Runnable command);提交任务。 ExecutorService，继承Executor: void shutdown();拒绝接受新任务，会把队列里面的任务也执行掉，如果任务中有中断判断是可以中断的，否则执行完。 List shutdownNow();拒绝接受新任务，返回没有执行的任务列表，如果任务中有中断判断，是可以中断的，否则就执行完。 Future submit(Callable); 提交一个有返回值的任务，submit的任务不能够被remove。 List","categories":[],"tags":[]},{"title":"Java内存管理","slug":"Java内存管理","date":"2016-11-10T07:44:13.000Z","updated":"2017-08-31T07:29:20.000Z","comments":true,"path":"2016/11/10/Java内存管理/","link":"","permalink":"http://www.merlin4io.com/2016/11/10/Java内存管理/","excerpt":"基本概念随机访问内存，寄存器，处理器，地址总线。地址总线是链接 处理器和内存的桥梁，地址总线控制了寻址范围，内存大小。用户空间，内核空间，内核空间为系统调用而存在，用户空间是除外操作系统之后的应用程序的内存空间。程序只能使用用户空间的数据，不能直接使用内核空间的数据。","text":"基本概念随机访问内存，寄存器，处理器，地址总线。地址总线是链接 处理器和内存的桥梁，地址总线控制了寻址范围，内存大小。用户空间，内核空间，内核空间为系统调用而存在，用户空间是除外操作系统之后的应用程序的内存空间。程序只能使用用户空间的数据，不能直接使用内核空间的数据。 JVM内存分配 方法区 虚拟机栈（java栈，线程栈） 本地方法区 java堆 程序计数器（PC寄存器） 直接内存（NIO） 方法区存放 classLoad家在的class文件，class原始信息，数据结构，以及运行时常量池（基本类型的变量和引用类型的引用）。可以通过maxPerm参数设置大小。 虚拟机栈，又称作java栈，每个线程都会创建一个java栈，每个java栈中有多个栈帧，当线程中调用一个方法，就会在java栈中存放一个栈帧，一个栈帧包括内部变量（局部变量），操作栈，返回值信息。java栈的栈顶为活动的栈帧（方法），当方法在次调用其他的方法就会在栈顶在创建一个新的栈帧，每个栈帧的操作栈只能访问自己自己栈帧的局部变量。java栈的数据是不共享的所以不存在同步锁问题。 本地方法区和java栈的功能基本相同，只是，调用的是本地方法。 java堆存放所有对象的实际内容，对象的引用存储在方法区或者java栈中，每个引用占用4个字节。可以通过-Xmx，-Xms设置堆的最大值和最小值。空间的管理有JVM来管理，对象的创建有程序创建，回收由垃圾回收器完成。 PC寄存器记录了线程当前运行的位置。 直接内存是java NIO使用的。 java堆垃圾回收 java堆中又分区分为 young区，old区，perm区，young区有氛围eden区，s0区，s1区。perm区存储类加载器加载的类对象，节本稳定，不怎么调用GC，但是如果反复加载也会导致perm区满，也会调用FullGC。 young区一般为整个堆区的四分之一，s0和s1区总和通常是young区的八分之一。新建的对象一般存储在eden区，当经过几次minorGC之后会有一部分放到s区，s区始终有一个是空余的，当s区满的时候，会检查old区剩余空间，如果剩余空间不足则会调用一次FullGC，如果空间充足则看JVM的配置，会调用一次minorGC，也有可能调用FullGC，然后把s区放不下的放到old区，old区放不下的时候就会调用FullGC。s区不满的时候，如果一些对象满足条件也会放到old区，比如说经过多少次minorGC之后仍然存活的对象。","categories":[],"tags":[]},{"title":"统一权限管理系统设计","slug":"统一权限管理系统设计","date":"2016-11-10T07:43:50.000Z","updated":"2016-11-13T03:41:31.000Z","comments":true,"path":"2016/11/10/统一权限管理系统设计/","link":"","permalink":"http://www.merlin4io.com/2016/11/10/统一权限管理系统设计/","excerpt":"","text":"几个问题 什么是统一权限管理系统？ 什么时候需要统一权限管理系统？ 统一权限管理系统能解决哪些问题？ 统一权限管理系统要解决哪些问题？ 如何让业务系统轻松的对接统一权限管理系统？ 如何满足业务系统的定制权限权限？ 定义统一权限管理系统，顾名思义，就是权限统一管理，统一登录。每个业务系统不用自己写登录，不用自己写权限管理，不用搭建自己的用户体系。 正在输入…….","categories":[],"tags":[]},{"title":"使用Mysql构建系统唯一标识","slug":"使用Mysql构建系统唯一标识","date":"2016-10-15T06:59:14.000Z","updated":"2016-10-15T07:07:14.000Z","comments":true,"path":"2016/10/15/使用Mysql构建系统唯一标识/","link":"","permalink":"http://www.merlin4io.com/2016/10/15/使用Mysql构建系统唯一标识/","excerpt":"","text":"或许你会有这样的需求，你需要一个唯一的标识，永远不会重复的，而且位数一样。这样使用mysql的唯一id就不太适合了。下面简单介绍一种方法。","categories":[],"tags":[]},{"title":"Groovy脚本初体验","slug":"Groovy脚本初体验","date":"2016-10-09T14:13:36.000Z","updated":"2016-11-10T07:46:43.000Z","comments":true,"path":"2016/10/09/Groovy脚本初体验/","link":"","permalink":"http://www.merlin4io.com/2016/10/09/Groovy脚本初体验/","excerpt":"","text":"groovy语言我了解的不多，语法我也不是特别清楚，这里提出的仅仅是一种解决问题的思路，这里的groovy脚本可以修改为javascript脚本等。只要java能够加载，能够执行这些脚本就可以。 脚本的编写与存储正在输入…….","categories":[],"tags":[{"name":"Groovy","slug":"Groovy","permalink":"http://www.merlin4io.com/tags/Groovy/"},{"name":"脚本","slug":"脚本","permalink":"http://www.merlin4io.com/tags/脚本/"}]},{"title":"多线程学习（三）之线程间通信","slug":"多线程学习（三）之线程间通信","date":"2016-10-02T09:30:47.000Z","updated":"2017-08-31T07:28:26.000Z","comments":true,"path":"2016/10/02/多线程学习（三）之线程间通信/","link":"","permalink":"http://www.merlin4io.com/2016/10/02/多线程学习（三）之线程间通信/","excerpt":"等待／通知机制多个线程之间如果没有等待／通知机制，那么多线程的通信就会很麻烦，比如说，两个线程A，B。A、B异步执行，但是在某个关键点，B线程要等待A线程某个关键点执行完才能继续执行，没有等待／通知机制，那么B线程只能一只循环检测A线程的关键点是否已经执行完成，就需要一直轮训。但是有了等待，通知机制，就可以不用去轮训，在关键点判断是否能够往下执行，不能久等待，A执行完关键点，发出通知就行了。","text":"等待／通知机制多个线程之间如果没有等待／通知机制，那么多线程的通信就会很麻烦，比如说，两个线程A，B。A、B异步执行，但是在某个关键点，B线程要等待A线程某个关键点执行完才能继续执行，没有等待／通知机制，那么B线程只能一只循环检测A线程的关键点是否已经执行完成，就需要一直轮训。但是有了等待，通知机制，就可以不用去轮训，在关键点判断是否能够往下执行，不能久等待，A执行完关键点，发出通知就行了。 wait(),notify(),notifyAll()三个方法调用之前都要先获得锁，不然会抛出IllegalMonitorStateException异常。wait(),notify(),之间的锁钥匙同一把锁才会有效。wait()方法调用之后，释放锁，进入阻塞block状态，notify（）方法调用之后，会把锁控制范围的代码执行完之后释放锁，其他调用wait()导致阻塞的线程才能获得锁。 nofity（）只会随机通知其中一个线程，notifyAll（）会通知所有线程，前提是，这些线程在竞争同一把锁，这下线程调用了wait()方法处于阻塞状态。wait(long),等待long时间之后自动唤醒。唤醒之后进入runable状态，等待cpu。 join()join()方法会等待等待内部线程结束之后外面的线程才结束，join（） 和sleep可以实现类似的功能，但实现方式不同，join()实现方式为wait（），notify（）方式，所以join会释放锁，但是sleep方式，不会释放锁。 ThreadLocal关于ThreadLocal可以查看其面的一篇http://www.merlin4io.com/2016/08/23/ThreadLocal%E5%88%9D%E4%BD%93%E9%AA%8C/ ReentrantLock可以实现synchronized类似的功能。 lock.lock()获取锁，lock.unlock(),使用lock的好处就是可以更精确的控制，哪些时候wait（），具体什么情况发出通知，wait的时候首先获取condition，然后调用condition.await(),通知的时候调用condition.signal(),同一个所下面可以控制具体什么情况wait（），什么情况signal（），更精确的通知具体的线程。 ReentrantReadWriteLock，读写互斥，读异步。写和其他的都互斥。使用方法lock.readLock.lock();lock.writeLock.lock();","categories":[],"tags":[{"name":"线程通信","slug":"线程通信","permalink":"http://www.merlin4io.com/tags/线程通信/"}]},{"title":"多线程学习（二）","slug":"多线程学习（二）","date":"2016-10-02T07:06:01.000Z","updated":"2017-08-31T07:28:19.000Z","comments":true,"path":"2016/10/02/多线程学习（二）/","link":"","permalink":"http://www.merlin4io.com/2016/10/02/多线程学习（二）/","excerpt":"共享变量的并发访问synchronized同步方法 方法内部的变量为线程安全变量 实例变量为非线程安全变量 同一个类的synchronized同步方法的锁事对象锁，是当前对象实例。 类A中有synchronized方法methodA（）和 非同步方法methodB(),则一个线程调用类A实例a的methodA()的同时，其他线程可以调用非同步方法methodB（）。多个线程多个类A的实例a,b,c,则多个线程可以异步调用a.methodA(),b.methodA(),c.methodA(),但同时只能有一个线程调用a.methodA(),因为synchronized方法为对象锁，不同的对象不同的锁。","text":"共享变量的并发访问synchronized同步方法 方法内部的变量为线程安全变量 实例变量为非线程安全变量 同一个类的synchronized同步方法的锁事对象锁，是当前对象实例。 类A中有synchronized方法methodA（）和 非同步方法methodB(),则一个线程调用类A实例a的methodA()的同时，其他线程可以调用非同步方法methodB（）。多个线程多个类A的实例a,b,c,则多个线程可以异步调用a.methodA(),b.methodA(),c.methodA(),但同时只能有一个线程调用a.methodA(),因为synchronized方法为对象锁，不同的对象不同的锁。类A中有synchronized方法methodA(),和synchronized方法methodB（），则在一个线程访问a的methodA（）的时候，其他线程不能访问methodB（），只能等到调用methodA（）的线程执行完或者放弃锁。 对共享的可变变量不进行同步操作，会导致数据的不一致，脏读。 synchronized方法具有重入锁功能，同样的类A中有synchronized方法methodA(),和synchronized方法methodB（），一个线程在执行methodA（）的时候，其他线程不能执行methodB（）方法，但在该线程可以在methodA（）调用methdodB（）方法。冲入锁，主要解决继承问题，比如说父类有一个synchronized methodC()方法，子类中重写了父类的methodC()方法，并且自类中调用了super.methodC()，并且也是synchronized方法，则如果没有重入锁，就永远获取不能执行父类的方法。 synchronized方法不具有继承性，父类方法为synchronized方法，子类没有生命为synchronized则自类方法不会同步。 synchronized同步语句块同步方法会导致一些无关的操作也会进入等待锁，另外同步方法同步的范围比较大，而同步语句块则可以更精确的控制需要同步操作的位置，提高效率。synchronized（this）的锁同样是对象锁。所以改代码块可所有synchronized方法是同步的。同一时刻只能有一个线程能够访问这些同步块（方法）中的其中一块（方法）。 synchronized（x）的锁为x，则x对应的同步方法用的是同一把锁，所以同时只能有一个线程访问这些同步代码块。 静态同步方法，静态同步语句块静态同步方法，和静态同步语句块的锁为class文件，所以和对象锁不互斥，可以异步访问。 死锁有两块共享资源 ，A，B，获取共享资源A需要先获得lock1，再获得lock2，获取共享资源B需要先获得lock2，然后获得lock1。有两个线程，thread1 先拿到lock1，thread2拿到lock2，thread1去获取lock2，拿不到锁，thread2去拿lock1，拿不到锁，导致一直不能往下运行，导致死锁。 锁改变sychronized(x),当作锁的对象(x)一般是不变的。如果用String当做锁，比如一开始用”123”当做锁，如果A线程获取到锁之后，把该字符串改为”234”,则如果B线程在检查锁的时候如果实在修改字符串之前，会获取不到锁，会等待锁，但是如果在修改之后去获取锁，就能够获取到锁，就会起不到同步的作用。但是如果x是一个对象，x中的某个属性改变不会影响锁。 volatile volatile主要解决的是多个线程之间的可见性，synchronized主要解决的事多个线程之间访问资源的同步性。 volatile是线程同步的轻量级实现，比synchronized性能要好，不过volatile只能修饰变量，synchronized可以修饰方法和代码块，随着jdk的升级，synchronized的性能也在提高。 volatile只能保证可见性，不能保证原子性。而synchronized可以保证原子性，也可以间接保证可见性。 多线程访问volatile变量是非阻塞的，而synchronized会出现阻塞。","categories":[],"tags":[{"name":"synchronized","slug":"synchronized","permalink":"http://www.merlin4io.com/tags/synchronized/"},{"name":"volatile","slug":"volatile","permalink":"http://www.merlin4io.com/tags/volatile/"}]},{"title":"多线程学习（一）","slug":"多线程学习（一）","date":"2016-09-30T14:38:30.000Z","updated":"2017-08-31T07:28:33.000Z","comments":true,"path":"2016/09/30/多线程学习（一）/","link":"","permalink":"http://www.merlin4io.com/2016/09/30/多线程学习（一）/","excerpt":"多线程技能进程和线程进程和线程的区别，进程是操作系统级别的，一个操作系统可以有很多进程。线程是进程级别的，一个进程可以有多个线程。进程有独立的运行内存，线程没有，线程之间的内存是共享的。 实现多线程的方法 可以继承Thread类，或者实现Runable接口。推荐实现Runable接口的方式，因为Java是单继承的，继承Thread类之后就不能继承其他的类了，Thread也是实现Runable接口方式来实现多线程的。","text":"多线程技能进程和线程进程和线程的区别，进程是操作系统级别的，一个操作系统可以有很多进程。线程是进程级别的，一个进程可以有多个线程。进程有独立的运行内存，线程没有，线程之间的内存是共享的。 实现多线程的方法 可以继承Thread类，或者实现Runable接口。推荐实现Runable接口的方式，因为Java是单继承的，继承Thread类之后就不能继承其他的类了，Thread也是实现Runable接口方式来实现多线程的。 非线程安全多个线程对同一个对象的同一个实例属性的操作，造成数据更新不同步，导致程序运行错误。非线程安全一定涉及到可变的共享变量。没有共享的可变变量就不存在线程安全问题。 线程的生命周期 new Thread（），之后线程进入new状态，分配内存。调用start（）方法进入runable状态，获得cpu之后进入running状态，调用wait（）方法进入block状态，调用notify（）方法进入runable状态，运行完进入死亡状态。 线程的基本方法： Thread.currentThread（），静态方法，获取当前运行的线程。 isAlive()，判断当前线程是否存活，start()方法调用之后true，调用之前false。 sleep(long),静态方法，让当前线程进入休息状态，如果有锁，该方法不会释放锁。 yield(),静态方法，让当前线程放弃cpu，进入runable状态，可能刚放弃cpu就又重新获得cpu。 interrupted()与isInterrupted() interrupted()方法为静态方法，判断当前线程是否被中断状态，另外调用该方法之后会清楚是否被中断的状态。 isInterrupted()方法，判断线程是否已经中断。可以在线程run（）方法外使用监控线程运行状态，也可以在run()方法内监控线程运行状态（外部是否发起中断线程命令），然后做相应的操作。 终止线程 线程运行完成自动终止。 异常法终止线程，调用线程的interrupt（）方法（非静态方法），run()方法内部判断线程是否是被中断状态，如果是，就内部抛出异常或者return终止线程。 sleep()中终止，当调用sleep（） 方法之后 调用线程的interrupt（）方法，就会抛出InterruptedException。终止线程。 stop（）方法（不推荐用）； 线程优先级线程优先级分为10个状态，1~10,数值越大，优先级越高，优先级高的线程有优先执行的机会，但不一定会优先执行，优先级具有随机性。另外优先级是可以继承的，该继承是指，A线程启动了B线程，则B线程有和A线程相同的优先级。线程的优先级默认为NOMAL的即数值是5。 守护线程 使用setDaemon(boolean)方法来设置一个线程是守护线程，守护线程随着最后一个线程的终止而中止，其他所有线程终止了，守护线程立马中止，不会再继续执行剩下的代码。","categories":[],"tags":[{"name":"线程安全","slug":"线程安全","permalink":"http://www.merlin4io.com/tags/线程安全/"}]},{"title":"单元测试的艺术","slug":"单元测试的艺术","date":"2016-09-30T14:38:01.000Z","updated":"2016-11-10T07:48:30.000Z","comments":true,"path":"2016/09/30/单元测试的艺术/","link":"","permalink":"http://www.merlin4io.com/2016/09/30/单元测试的艺术/","excerpt":"","text":"不管是大项目还是小项目，都需要单元测试来保证代码的质量，有些单元测试不是明确的测试形式，比如说http接口，可以启动服务器，通过浏览器或者curl或者其他发请求工具，发起测试，然后跟踪问题，解决问题，但是启动项目可能话费的时间比较长。而单元测试使用的好，可以快速启动只是加载自己需要的资源，缩小资源范围，提高效率。单元测试终于麻烦，繁琐。 正在输入…….","categories":[],"tags":[]},{"title":"定时任务管理系统设计","slug":"定时任务管理系统设计","date":"2016-09-30T14:37:43.000Z","updated":"2017-08-31T07:28:09.000Z","comments":true,"path":"2016/09/30/定时任务管理系统设计/","link":"","permalink":"http://www.merlin4io.com/2016/09/30/定时任务管理系统设计/","excerpt":"为什么需要定时任务？业务系统需要自动完成一些工作，定时处理一些业务，比如说，订单7天未支付自动关闭，月底统计订单数据量，每天统计用户增长量等，涉及到需要系统自动完成的，不需要人为操作的，都可以用定时任务来做，或者说，人为来做比较麻烦的。 什么情况下定时任务需要管理？当你只有一个系统的时候，可能不需要一个系统来管理你的定时任务，你可能自己系统来管理就行了，或者说，你系统的定时任务很少，自己管理就足够了。 但是通常情况下，因为涉及到定时任务，需要确定，如果定时任务没有执行，是否需要手动触发，如果定时任务涉及外部数据的时候，执行失败，当修复好外部数据之后，是否需要重新发起执行，这就涉及到，你的定时任务是否都需要一个外部入口，手动调用。这样的话，因为系统不能随时发布重新调整cron表达式，重新执行，所以我们需要来管理。当然这里说的定时任务时通过spring的Scheduled注解来实现的方式的定时任务，如果你的实现方式是其他类型的定时任务，可以思考下面的方法是否能够通用。","text":"为什么需要定时任务？业务系统需要自动完成一些工作，定时处理一些业务，比如说，订单7天未支付自动关闭，月底统计订单数据量，每天统计用户增长量等，涉及到需要系统自动完成的，不需要人为操作的，都可以用定时任务来做，或者说，人为来做比较麻烦的。 什么情况下定时任务需要管理？当你只有一个系统的时候，可能不需要一个系统来管理你的定时任务，你可能自己系统来管理就行了，或者说，你系统的定时任务很少，自己管理就足够了。 但是通常情况下，因为涉及到定时任务，需要确定，如果定时任务没有执行，是否需要手动触发，如果定时任务涉及外部数据的时候，执行失败，当修复好外部数据之后，是否需要重新发起执行，这就涉及到，你的定时任务是否都需要一个外部入口，手动调用。这样的话，因为系统不能随时发布重新调整cron表达式，重新执行，所以我们需要来管理。当然这里说的定时任务时通过spring的Scheduled注解来实现的方式的定时任务，如果你的实现方式是其他类型的定时任务，可以思考下面的方法是否能够通用。 我们需要一个什么样的定时任务管理系统？ 有多个业务系统。 每个业务系统都有或多或少的定时任务。 定时任务能够动态的禁止运行。 定时任务能够手动触发。 定时任务能够动态修改执行的cron表达式。 定时任务执行结果反馈（执行成功，还是执行失败）。 首先涉及到多个业务系统，那就需要系统交互，多个业务系统和自身定时任务系统的交互，交互方式可以用dubbo方式的soa来解决。 每个业务系统有多个定时任务，所以定时任务系统需要记录各个系统名称，各个定时任务名称。 能够动态的禁止定时任务运行和手动触发，所以需要管理每个定时任务的状态。 能够动态修改cron表达式，所以需要记录cron表达式，并且在cron表达式的时间执行定时任务。 定时任务执行结果需要反馈，所以需要记录定时任务执行的结果。 如何实现？既然需要业务系统和task系统之间的调用，那么业务系统就需要暴漏soa接口，task系统也要暴漏soa接口，但是为了做到业务系统使用简单，业务系统的soa接口，使用task系统提供的jar包提供，然后通过扩展ioc容器启动过程，暴漏接口。在定时任务执行完成之后回调task系统的接口，通知定时任务执行的结果。task系统展示之行结果。 task系统存储所有的定时任务，在系统启动之后，扫描所有的定时任务，检查定时任务是否准备就绪，准备就绪就把当前定时任务当作一个job交给schedule，schedule检查该定时任务是否已经在执行计划中了，如果不在就加入到执行计划中，按照cron指定的表达式去按时执行任务。在后台暂停，定时任务时，通知schedule终止定时任务。","categories":[],"tags":[]},{"title":"Spring源码学习（一）","slug":"Spring源码学习（一）","date":"2016-09-11T15:09:47.000Z","updated":"2016-09-11T15:09:47.000Z","comments":true,"path":"2016/09/11/Spring源码学习（一）/","link":"","permalink":"http://www.merlin4io.com/2016/09/11/Spring源码学习（一）/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"分布式锁之数据库实现","slug":"分布式锁之数据库实现","date":"2016-09-06T10:51:32.000Z","updated":"2017-08-31T07:29:01.000Z","comments":true,"path":"2016/09/06/分布式锁之数据库实现/","link":"","permalink":"http://www.merlin4io.com/2016/09/06/分布式锁之数据库实现/","excerpt":"分布式锁和集群锁，什么是分布式锁？分布式锁是在分布式系统将常用到的，为了解决分布式系统之间资源访问冲突问题的。简单来说就是为了解决资源访问冲突的，或者是防止并发执行的。分布式锁的实现方式都是在一个公共的地方存一个标志代表一把锁，谁先存储成功，谁就获得锁，自己的程序之行结束之后释放锁，没有获得锁的可以直接失败，或者等待锁。分布式锁，和集群锁在我看来没有太大区别，要解决的问题一样，解决问题的方式也大致相同。 实现分布式锁的方式有很多种，可以用redis，memcached，zookeeper，数据库等来实现，今天简单的来说说试用数据库实现分布式锁，但是这种方式不常用，或者说基本不用（因为用数据库作为公共资源锁比较重，另外如果用也只是用做集群锁，分布式锁，用这个来实现，还是比较累的）。","text":"分布式锁和集群锁，什么是分布式锁？分布式锁是在分布式系统将常用到的，为了解决分布式系统之间资源访问冲突问题的。简单来说就是为了解决资源访问冲突的，或者是防止并发执行的。分布式锁的实现方式都是在一个公共的地方存一个标志代表一把锁，谁先存储成功，谁就获得锁，自己的程序之行结束之后释放锁，没有获得锁的可以直接失败，或者等待锁。分布式锁，和集群锁在我看来没有太大区别，要解决的问题一样，解决问题的方式也大致相同。 实现分布式锁的方式有很多种，可以用redis，memcached，zookeeper，数据库等来实现，今天简单的来说说试用数据库实现分布式锁，但是这种方式不常用，或者说基本不用（因为用数据库作为公共资源锁比较重，另外如果用也只是用做集群锁，分布式锁，用这个来实现，还是比较累的）。 数据库结构CREATE TABLE `one_by_one` ( `biz_type` varchar(64) NOT NULL COMMENT &apos;业务类型&apos;, `biz_id` varchar(64) NOT NULL COMMENT &apos;业务ID&apos;, `method` varchar(64) DEFAULT NULL COMMENT &apos;方法名称&apos;, `create_time` datetime DEFAULT NULL COMMENT &apos;创建时间&apos;, PRIMARY KEY (`biz_type`,`biz_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;一个接一个处理记录表&apos;; 提供了两个基本的插入，删除方法，不使用数据库，只要把这里面的实现改掉就可以了，实现可以用redis，memcached，zookeeper都可以，后续会更新。 void save(OneByOne oneByOne);// 获取锁 void delete(OneByOne oneByOne);// 释放锁 使用方法锁的使用方法无外乎，获取锁，执行业务逻辑，释放锁，使用数据库实现的方式也一样。demo如下，数据库存储部分没有实现，如果要使用，修改save 和delete方法，真实处理数据库就行了。其实其他方式的锁，也可以这么做，save 和 delete 分别为获得锁，和释放锁。 代码地址：https://github.com/xia-zhou/demo-cydeer.git 在onebyone包下面。 简单代码如下： 锁实体类：对应的set，get方法取掉了。 package com.cydeer.demo.onebyone.api.domain; import java.util.Date; /** * Created by zhangsong on 16/9/11. */ public class OneByOne { /** * 业务类型 */ private String bizType; /** * 业务Id 一般为帐号ID,和上面的bizType组成联合主键 */ private String bizId; /** * 方法名称 */ private String method; /** * 创建时间 */ private Date createTime; /** * @param bizType 业务类型 * @param bizId 业务Id * @param method 方法名称 */ public OneByOne(String bizType, String bizId, String method) { this.bizType = bizType; this.bizId = bizId; this.method = method; } } 业务回调接口： package com.cydeer.demo.onebyone.api; /** * Created by zhangsong on 16/9/11. */ public interface CallBack&lt;T&gt; { /** * 业务处理回调,在锁范围内执行的业务逻辑 * * @param &lt;T&gt; * @return */ &lt;T&gt; T invoke(); } 锁使用对外接口： package com.cydeer.demo.onebyone.api; import com.cydeer.demo.onebyone.api.domain.OneByOne; /** * Created by zhangsong on 16/9/11. */ public interface OneByOneExecutor { /** * @param oneByOne 业务场景,不同的业务场景不同的锁 * @param callBack 实际在获取到锁的范围内执行的业务逻辑 * @param &lt;T&gt; 业务逻辑的返回结果。 * @return */ &lt;T&gt; T execute(OneByOne oneByOne, CallBack&lt;T&gt; callBack); } 锁使用对外接口实现类： package com.cydeer.demo.onebyone.impl; import com.cydeer.demo.onebyone.api.CallBack; import com.cydeer.demo.onebyone.api.ObtainLockException; import com.cydeer.demo.onebyone.api.OneByOneExecutor; import com.cydeer.demo.onebyone.api.domain.OneByOne; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.jdbc.BadSqlGrammarException; import java.util.Date; /** * Created by zhangsong on 16/9/11. */ public class OneByOneExecutorImpl implements OneByOneExecutor { /** * Logger */ private static final Logger LOG = LoggerFactory.getLogger(OneByOneExecutorImpl.class); /** * 插入结果 */ private ThreadLocal&lt;Boolean&gt; insertResult = new ThreadLocal&lt;Boolean&gt;(); /** * 业务描述 */ private ThreadLocal&lt;String&gt; description = new ThreadLocal&lt;String&gt;(); @Override public &lt;T&gt; T execute(OneByOne oneByOne, CallBack&lt;T&gt; callBack) { StringBuilder builder = new StringBuilder(64); builder.append(oneByOne.getBizType()).append(&quot;-&quot;).append(oneByOne.getBizId()).append(&quot;-&quot;) .append(oneByOne.getMethod()); this.description.set(builder.toString()); try { this.beforeInvoke(oneByOne); // 前处理 return callBack.invoke(); // 业务逻辑 } finally { this.afterInvoke(oneByOne); // 后处理 } } /** * 前处理&lt;br&gt; * 尝试插入处理记录:加锁 * * @param oneByOne 一个接一个业务实体 */ private void beforeInvoke(final OneByOne oneByOne) { try { insertResult.set(Boolean.TRUE); // 插入处理记录 oneByOne.setCreateTime(new Date()); // 创建时间 save(oneByOne); } catch (BadSqlGrammarException e) { // SQL语法错误或表不存在: 直接执行业务逻辑,不抛异常 insertResult.set(Boolean.FALSE); if (LOG.isWarnEnabled()) { LOG.warn(description.get() + &quot;插处理记录失败&quot;, e); } } catch (Throwable t) { insertResult.set(Boolean.FALSE); if (LOG.isWarnEnabled()) { LOG.warn(description.get() + &quot;插处理记录失败&quot;, t); } // 抛出异常 throw new ObtainLockException(&quot;业务正在处理中&quot;); } } /** * 后处理&lt;br&gt; * 删除处理记录:释放锁 * * @param oneByOne 一个接一个业务实体 */ private void afterInvoke(final OneByOne oneByOne) { // beforeInvoke时插入失败,不需删除处理记录 if (!insertResult.get()) { return; } try { // 删除处理记录 delete(oneByOne); } catch (Throwable t) { LOG.error(description.get() + &quot;删处理记录失败&quot;, t); } finally { // 清理 description.set(null); insertResult.set(null); } } private void save(OneByOne oneByOne) { System.out.println(&quot;存储数据库,存储成功获得锁,存储失败获取锁失败&quot;); } private void delete(OneByOne oneByOne) { System.out.println(&quot;删除记录,释放锁&quot;); } } 自定义异常： package com.cydeer.demo.onebyone.api; /** * Created by zhangsong on 16/9/11. * 获取锁异常 */ public class ObtainLockException extends RuntimeException { public ObtainLockException(String message) { super(message); } } 模拟调用者： package com.cydeer.demo.onebyone; import com.cydeer.demo.onebyone.api.CallBack; import com.cydeer.demo.onebyone.api.OneByOneExecutor; import com.cydeer.demo.onebyone.api.domain.OneByOne; import com.cydeer.demo.onebyone.impl.OneByOneExecutorImpl; /** * Created by zhangsong on 16/9/11. */ public class MainClient { public static void main(String[] args) { OneByOneExecutor oneByOneExecutor = new OneByOneExecutorImpl(); Object object = oneByOneExecutor .execute(new OneByOne(&quot;SETTLE_TASK&quot;, &quot;201609&quot;, &quot;9月份定时任务执行&quot;), new CallBack&lt;Object&gt;() { @Override public Object invoke() { System.out.println(&quot;真正的业务逻辑代码&quot;); // 业务执行结果 Object o = new Object(); return o; } }); } }","categories":[],"tags":[{"name":"集群锁","slug":"集群锁","permalink":"http://www.merlin4io.com/tags/集群锁/"},{"name":"分布式锁","slug":"分布式锁","permalink":"http://www.merlin4io.com/tags/分布式锁/"},{"name":"OneByOne","slug":"OneByOne","permalink":"http://www.merlin4io.com/tags/OneByOne/"}]},{"title":"微服务体系（一）","slug":"微服务体系（一）","date":"2016-09-06T10:51:10.000Z","updated":"2016-09-11T15:06:38.000Z","comments":true,"path":"2016/09/06/微服务体系（一）/","link":"","permalink":"http://www.merlin4io.com/2016/09/06/微服务体系（一）/","excerpt":"","text":"正在输入……","categories":[],"tags":[]},{"title":"常用日志查看命令与集群监控命令","slug":"常用日志查看命令与集群监控命令","date":"2016-09-05T04:41:21.000Z","updated":"2016-09-06T10:08:37.000Z","comments":true,"path":"2016/09/05/常用日志查看命令与集群监控命令/","link":"","permalink":"http://www.merlin4io.com/2016/09/05/常用日志查看命令与集群监控命令/","excerpt":"","text":"查看日志常用命令cd、ls、mkdir、rm、rm -rf、cp、mv这些简单的不再多说。 scp 把本机文件settle.war拷贝到远程主机host下的／homt/root下面： scp /home/war/settle.war root@host:/home/root 把远程文件settle.war拷贝到本机，名字为settleLocal.war： scp root@host:/homt/root/settle.war /homt/war/settleLocal.war cat 查看文件内容，cat -n 会显示文件的行号。 cat命令执行之后不能够再进行交互和控制。对应的分页查看命令more，则可以控制显示下一页，上一页，上一屏，下一屏内容。less还可以使用／关键字进行查找。 vi 编辑文本，也可以查看文本，查找，使用／关键字来查找。编辑完之后可以保存退出，或者直接退出。 find / -name &apos;&apos; tail -n 1000 stmt.log 显示末尾1000行 tail -f stmt.log 持续显示日志内容，有新的日志会自动显示。 head 和 tail类似。 sort sort -n 按照数字正序排列，sort -n -r 倒序排列 grep &quot;关键字&quot; stmt.log -A 100 -B 300 关键字前100行 后300行 grep -c &quot;关键字&quot; stmt.log 统计关键字出现的次数 tar 解压，归档文件使用 系统监控常用命令uptime 查看系统负载，每个cpu当前的活动线程数不大于3可以认为是正常的，大于5说明负载已经有点高了，三个数值分别代表1分钟、5分钟、15分钟内的load值。 top | grep Cpu 查看各个cpu的各个时间消耗，cpu的利用率 top -p 2864 查看指定进程 df -h 按单位格式化输出生育磁盘空间。 du d 1 -h /hont/root 按单位格式化输出文件夹下文件的大小,深度为1 free -m 以兆格式输出内存使用率。 ping 心跳检测 iostat -d -k 查看系统的io情况 traffic、sar -n DEV 1 1 监测网络。 talnet 远程连接 netstat 端口使用状态 ifconfig ip地址 iptables 防火墙 ps -ef | grep nignix 查看进程 ps -aux | grep tomcat 查看进程","categories":[],"tags":[{"name":"日志操作","slug":"日志操作","permalink":"http://www.merlin4io.com/tags/日志操作/"},{"name":"系统监控","slug":"系统监控","permalink":"http://www.merlin4io.com/tags/系统监控/"}]},{"title":"Memcached缓存小记","slug":"Memcached缓存小记","date":"2016-09-05T04:38:36.000Z","updated":"2017-08-31T07:41:46.000Z","comments":true,"path":"2016/09/05/Memcached缓存小记/","link":"","permalink":"http://www.merlin4io.com/2016/09/05/Memcached缓存小记/","excerpt":"为什么用缓存？为什么用缓存？什么情况下用缓存？ 当对数据的读取很频繁，数据又不经常变化，数据库压力比较大的情况下，使用缓存可以很好的解决问题。缓存有多重，有本地缓存（ehcached），但线程缓存（redis），分布式缓存（memcached），各有各的优势，各有各的适用范围，比如说小系统，单机模式，本地缓存足够了，不用考虑多台机子之间的同步，使用成本也低。再大一点可以使用redis，redis的数据类型比较广泛，有String,list,map,set,集合类型数据，redis本身会做压缩，占用的内存会比较小。","text":"为什么用缓存？为什么用缓存？什么情况下用缓存？ 当对数据的读取很频繁，数据又不经常变化，数据库压力比较大的情况下，使用缓存可以很好的解决问题。缓存有多重，有本地缓存（ehcached），但线程缓存（redis），分布式缓存（memcached），各有各的优势，各有各的适用范围，比如说小系统，单机模式，本地缓存足够了，不用考虑多台机子之间的同步，使用成本也低。再大一点可以使用redis，redis的数据类型比较广泛，有String,list,map,set,集合类型数据，redis本身会做压缩，占用的内存会比较小。 数据库的连接数； jvm中的线程数； 高数据访问量放到缓存中； 缓存数据持久化； redis有两种持久化方式：rdb和aof，是一种snapshop（快照）的方式存储数据，对应产生dump.rdb文件，可配置当有多少个key发生变化的时候，隔多久保存快照一次。aof的方式即append－of－file，是把操作命令写到文件中，可以控制每次发生操作命令就写入，或者每隔几秒钟写入一次。AOF(Append-Only File)比RDB方式有更好的持久化性，aof类似数据库的binlog。 memcached只支持key，value的数据类型，复杂数据类型需要使用者自己解析。memcached客户端比较重，服务端比较轻，分布式的实现也是客户端完成的。redis使用起来简单，方便入手快，memcached使用起来比较繁琐。redis和spring集成的比较好，堪称完美，但是memcached和spring集成的就没那么好了，有不同的客户端，各个客户端的性能和稳定性也不同，要按照自己应用的需求来使用相应的客户端，但是总的来说用起来还是没那么方便，所以仿照别人写了一个基于springAOP，采用注解的方式方便使用缓存。 下面先简单的介绍一下memcached： 优势： 协议简单，基于文本的协议。 基于libevent的事件处理，封装成统一的接口。 内置内存存储方式，提高性能。 不互通信的分布式，服务器端不支持分布式，主要通过客户端来实现。 Memcached删除数据时数据不会真正从memcached中消失。Memcached不会释放已分配的内存。记录超时后，客户端就无法再看见该记录（invisible 透明），其存储空间即可重复使用。 Lazy Expriationmemcached内部不会监视记录是否过期，而是在get时查看记录的时间戳，检查记录是否过期。这种技术称为lazy expiration.因此memcached不会再过期监视上耗费CPU时间。 对于缓存存储容量满的情况下的删除需要考虑多种机制，一方面是按队列机制，一方面应该对应缓存对象本身的优先级，根据缓存对象的优先级进行对象的删除。 基于AOP的注解实现缓存两个注解，存储缓存注解： package com.cydeer.demo.memcached.annotation; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * Created by zhangsong on 16/1/19. */ @Target({ ElementType.METHOD, ElementType.TYPE }) @Retention(RetentionPolicy.RUNTIME) public @interface CacheableExt { /** * @return 扩展 keys，如果同一个方法里面有相同的参数，防止key重复 暂时未开启 */ String keyExt() default &quot;&quot;; /** * 使用规则：&lt;BR&gt; * 1. 返回的是数组类型，数组中的每个值与参数中的对象一一对应。不过数组的长度允许与参数个数不同，&lt;BR&gt; * 但实际运行时将以参数长度来自动匹配数据中相应位置的值；&lt;BR&gt; * 2. 数组中的每个值，以英文逗号（,）分隔，用来区分对象中系列化要包含的多个字段；&lt;BR&gt; * 3. 对于参数中若有对象不需要排除字段的，请以空字符串定义；&lt;BR&gt; * 4. 复杂DTO对象中不支持再有复杂对象作为因子Key；&lt;BR&gt; * * @return 返回缓存排除JSON系统化KEY时的字段列表 */ String[] keys() default {}; /** * @return 设置缓存过期时间，默认 60 秒 */ int expire() default 60; } 缓存失效注解： package com.cydeer.demo.memcached.annotation; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * Created by zhangsong on 16/1/19. */ @Target({ ElementType.METHOD, ElementType.TYPE }) @Retention(RetentionPolicy.RUNTIME) public @interface CacheEvictExt { /** * @return 扩展 keys，如果同一个方法里面有相同的参数，防止key重复 暂时未开启 */ String keyExt() default &quot;&quot;; /** * 使用规则：&lt;BR&gt; * 1. 返回的是数组类型，数组中的每个值与参数中的对象一一对应。不过数组的长度允许与参数个数不同，&lt;BR&gt; * 但实际运行时将以参数长度来自动匹配数据中相应位置的值；&lt;BR&gt; * 2. 数组中的每个值，以英文逗号（,）分隔，用来区分对象中系列化要包含的多个字段；&lt;BR&gt; * 3. 对于参数中若有对象不需要排除字段的，请以空字符串定义；&lt;BR&gt; * 4. 复杂DTO对象中不支持再有复杂对象作为因子Key；&lt;BR&gt; * * @return 返回缓存排除JSON系统化KEY时的字段列表 */ String[] keys() default {}; /** * @return 清空key的情况下可能会需要清空多个key, 比如用户信息, 缓存可能为根据手机号缓存, * 也可能根据用户id缓存,那么修改的时候就需要清空多个key */ String[] secondKeys() default {}; } 对应的最重要的AOP类： 两个方法，一个切面处理存储缓存，一个处理失效缓存，由于memcached不支持null值序列化，所以使用了一个静态内部类来替代null。另外特殊场景，清除缓存的时候有可能会清楚多个缓存，现在仅支持一次清除两个缓存。比如说：用户信息, 缓存可能为根据手机号缓存, 也可能根据用户id缓存,那么修改的时候就需要清空多个key。其实最重要的方法还是生成key的方法。 package com.cydeer.demo.memcached.aop; import com.cydeer.demo.memcached.annotation.CacheEvictExt; import com.cydeer.demo.memcached.annotation.CacheKeyUtils; import com.cydeer.demo.memcached.annotation.CacheableExt; import com.cydeer.demo.memcached.client.CacheApi; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.reflect.MethodSignature; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.io.Serializable; import java.lang.reflect.Method; /** * Created by zhangsong on 16/1/20. */ @Aspect public class MemcachedExtAop { private final static Logger LOGGER = LoggerFactory.getLogger(MemcachedExtAop.class); private CacheableExt cacheableExt; private CacheEvictExt cacheEvictExt; private CacheApi cacheApi; @Around(&quot;@annotation(com.cydeer.demo.memcached.annotation.CacheableExt)&quot;) private Object cacheableProcess(ProceedingJoinPoint jp) throws Throwable { Class&lt;?&gt; targetClz = jp.getTarget().getClass(); String methodName = jp.getSignature().getName(); if (!(jp.getSignature() instanceof MethodSignature)) { LOGGER.warn(&quot;该方法接口无法启用缓存功能: {}&quot;, jp.getSignature().toLongString()); return jp.proceed(); } MethodSignature methodSign = (MethodSignature) jp.getSignature(); Method method = targetClz.getMethod(methodName, methodSign.getParameterTypes()); cacheableExt = method.getAnnotation(CacheableExt.class); if (cacheableExt == null) { return jp.proceed(); } if (cacheableExt.expire() &gt; 0) { String cacheKey = CacheKeyUtils .buildCacheKey(cacheableExt.keyExt(), cacheableExt.keys(), targetClz, jp.getArgs()); Object result = cacheApi.get(cacheKey); if (result == null) { result = jp.proceed(); result = result == null ? Blank.INST : result; cacheApi.put(cacheKey, result, cacheableExt.expire()); } return result instanceof Blank ? null : result; } else { return jp.proceed(); } } @Around(&quot;@annotation(com.cydeer.demo.memcached.annotation.CacheEvictExt)&quot;) private Object cacheevictProcess(ProceedingJoinPoint jp) throws Throwable { Class&lt;?&gt; targetClz = jp.getTarget().getClass(); String methodName = jp.getSignature().getName(); if (!(jp.getSignature() instanceof MethodSignature)) { LOGGER.warn(&quot;该方法接口无法启用缓存功能: {}&quot;, jp.getSignature().toLongString()); return jp.proceed(); } MethodSignature methodSign = (MethodSignature) jp.getSignature(); Method method = targetClz.getMethod(methodName, methodSign.getParameterTypes()); cacheEvictExt = method.getAnnotation(CacheEvictExt.class); if (cacheEvictExt != null) { String cacheKey = CacheKeyUtils .buildCacheKey(cacheEvictExt.keyExt(), cacheEvictExt.keys(), targetClz, jp.getArgs()); cacheApi.evict(cacheKey); // 清除 第二个 key if (cacheEvictExt.secondKeys() == null || cacheEvictExt.secondKeys().length &gt; 0) { String cacheKeyBackUp = CacheKeyUtils .buildCacheKey(cacheEvictExt.keyExt(), cacheEvictExt.secondKeys(), targetClz, jp.getArgs()); cacheApi.evict(cacheKeyBackUp); } } return jp.proceed(); } public void setCacheApi(CacheApi cacheApi) { this.cacheApi = cacheApi; } private static class Blank implements Serializable { private static final long serialVersionUID = 3203712628835590212L; private static final MemcachedExtAop.Blank INST = new MemcachedExtAop.Blank(); private Blank() { } } } 缓存的key的生成方式： 使用类的全类名，然后加上扩展key解决万一同一个类中缓存的参数一致的问题，然后加上参数名再加上参数值作为key，中间使用下划线拼接。 多个参数使用方式：keys={“key1”,”key2”,”key3”}; 复杂类型参数使用方式，比如说两个参数，user,address两个参数都是对象，user有userId,phone,address有email，code，使用方式：keys={“userId,phone”,”email,code”}; package com.cydeer.demo.memcached.annotation; import org.apache.commons.lang3.ClassUtils; import org.apache.commons.lang3.StringUtils; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.lang.reflect.Field; import java.util.*; /** * Created by zhangsong on 16/1/19. */ public class CacheKeyUtils { private final static Logger LOGGER = LoggerFactory.getLogger(CacheKeyUtils.class); private static final String UNDER_LINE = &quot;_&quot;; private static final String POINT = &quot;.&quot;; /** * 类加方法名的唯一标识 * * @param args * @return */ public static String buildCacheKey(String keyExt, String[] keys, Class&lt;?&gt; targetClz, Object[] args) { String argsKey = &quot;&quot;; if (args != null) { StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; args.length; i++) { Object arg = args[i]; // 对于 args 有参数的方法，同时又是JSON生成键值的，必须定义包含的key值因子 if (keys.length &lt; 1) throw new IllegalArgumentException(&quot;请定义 keys 的缓存属性&quot;); if (arg == null) { sb.append(UNDER_LINE).append(&quot;null&quot;); } else { if (i &lt; keys.length &amp;&amp; StringUtils.isNotBlank(keys[i])) { if (isBassClassType(arg.getClass())) { sb.append(UNDER_LINE).append(String.valueOf(keys[i])); sb.append(UNDER_LINE).append(String.valueOf(arg)); } else { Set&lt;String&gt; includeFields = new HashSet&lt;String&gt;(Arrays.asList(StringUtils.split( keys[i], &quot;,&quot;))); Class&lt;?&gt; argClz = arg.getClass(); //对于 Map 或 Collection，不支持 //其他DTO对象排除复杂类型的属性数据 if (!Map.class.isAssignableFrom(argClz) &amp;&amp; !Collection.class.isAssignableFrom(argClz)) { Field[] argFields = arg.getClass().getDeclaredFields(); for (Field field : argFields) { if (!isBassClassType(field.getType())) { includeFields.remove(field.getName()); } else if (includeFields.contains(field.getName())) { field.setAccessible(true); try { sb.append(UNDER_LINE).append(String.valueOf(field.get(arg))); } catch (IllegalAccessException e) { throw new IllegalArgumentException(&quot;key对应的值获取不到，key:&quot; + field.getName()); } } } } } } } } argsKey = sb.toString(); argsKey = StringUtils.removeStart(argsKey, UNDER_LINE); } String wholeKey = StringUtils.isEmpty(keyExt) ? StringUtils.join(new String[] { targetClz.getName(), argsKey }, UNDER_LINE) : StringUtils.join(new String[] { targetClz.getName(), keyExt, argsKey }, UNDER_LINE); LOGGER.info(&quot;Cacheable for key : {}&quot;, wholeKey); return wholeKey; } private static boolean isBassClassType(Class&lt;?&gt; type) { return ClassUtils.isPrimitiveOrWrapper(type) || type == String.class; } } 以及对应的memcached客户端简单封装： 接口： package com.cydeer.demo.memcached.client; /** * Created by zhangsong on 16/1/19. */ public interface CacheApi { Object get(String key); &lt;T&gt; T get(String key, Class&lt;T&gt; type); void put(String key, Object value); void put(String key, Object value, int expire); void evict(String key); } 实现： package com.cydeer.demo.memcached.client; import net.spy.memcached.MemcachedClient; import net.spy.memcached.internal.OperationFuture; /** * Created by zhangsong on 16/1/19. */ public class MemcachedClientExt implements CacheApi { /** * 使用net.spy.memcached.MemcachedClient 的客户端 */ private MemcachedClient client; /** * key 的前缀，防止不同应用使用相同的缓存服务器，key重复。 */ private String keyPrefix; private int defaultExpire; public MemcachedClientExt(MemcachedClient client, String keyPrefix, int defaultExpire) { this.client = client; this.keyPrefix = keyPrefix + &quot;.&quot;; this.defaultExpire = defaultExpire; } @Override public Object get(String key) { return client.get(buildKey(key)); } @Override public &lt;T&gt; T get(String key, Class&lt;T&gt; type) { Object value = this.get(key); if (value != null &amp;&amp; type != null &amp;&amp; !type.isInstance(value)) { throw new IllegalStateException(&quot;Cached value is not of required type [&quot; + type.getName() + &quot;]: &quot; + value); } return (T) value; } @Override public void put(String key, Object value) { this.put(key, value, defaultExpire); } @Override public void put(String key, Object value, int expire) { OperationFuture&lt;Boolean&gt; res = client.set(buildKey(key), expire, value); if (res.isDone()) { //System.out.println(&quot;zhaong&quot;); } } @Override public void evict(String key) { client.delete(buildKey(key)); } private String buildKey(String key) { return keyPrefix + key; } } 工厂类： package com.cydeer.demo.memcached.client; import net.spy.memcached.AddrUtil; import net.spy.memcached.MemcachedClient; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.FactoryBean; import org.springframework.beans.factory.InitializingBean; import org.springframework.util.StringUtils; /** * Created by zhangsong on 16/1/19. */ public class MemcachedClientFactory implements FactoryBean&lt;MemcachedClientExt&gt;, InitializingBean { private final static Logger LOGGER = LoggerFactory.getLogger(MemcachedClientFactory.class); private MemcachedClientExt memcachedClientExt; private String servers; private String keyPrefix; private int defaultExpire; /*private long timeOut; private boolean auth; private String username; private String password;*/ @Override public MemcachedClientExt getObject() throws Exception { return memcachedClientExt; } @Override public Class&lt;?&gt; getObjectType() { return MemcachedClientExt.class; } @Override public boolean isSingleton() { return true; } @Override public void afterPropertiesSet() throws Exception { if (StringUtils.isEmpty(servers)) { throw new IllegalArgumentException(&quot;No servers set&quot;); } if (StringUtils.isEmpty(keyPrefix)) { throw new IllegalArgumentException(&quot;Please set key prefux&quot;); } if (defaultExpire == 0) { // 过期时间 默认设置为1分钟（60秒） defaultExpire = 60; } MemcachedClient client = new MemcachedClient(AddrUtil.getAddresses(servers)); this.memcachedClientExt = new MemcachedClientExt(client, keyPrefix, defaultExpire); LOGGER.info(&quot;MemcachedClientExt has init&quot;); } public void setServers(String servers) { this.servers = servers; } public void setKeyPrefix(String keyPrefix) { this.keyPrefix = keyPrefix; } public void setDefaultExpire(int defaultExpire) { this.defaultExpire = defaultExpire; } } 配置文件： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt; &lt;!-- 对包中的所有类进行扫描类上的注解，以完成Bean创建和自动依赖注入的功能 需要更改 --&gt; &lt;context:component-scan base-package=&quot;com.cydeer.demo&quot;/&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;bean id=&quot;containerConfProperty&quot; class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt; &lt;!-- 是否忽略不可解析的 --&gt; &lt;property name=&quot;ignoreUnresolvablePlaceholders&quot; value=&quot;true&quot;/&gt; &lt;!-- 多个locations， 单个location &lt;value&gt; --&gt; &lt;property name=&quot;locations&quot;&gt; &lt;list&gt; &lt;value&gt;classpath*:/conf/*.conf&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;cacheApi&quot; class=&quot;com.cydeer.demo.memcached.client.MemcachedClientFactory&quot;&gt; &lt;property name=&quot;servers&quot; value=&quot;${memcached.api.servers}&quot;/&gt; &lt;property name=&quot;keyPrefix&quot; value=&quot;${app.name}&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;cacheAspect&quot; class=&quot;com.cydeer.demo.memcached.aop.MemcachedExtAop&quot;&gt; &lt;property name=&quot;cacheApi&quot; ref=&quot;cacheApi&quot;/&gt; &lt;/bean&gt; &lt;/beans&gt; conf文件： app.name=cydeer memcached.api.servers=localhost:11211 代码地址（包含测试程序）：https://github.com/xia-zhou/demo-cydeer.git 在memcached包下面","categories":[],"tags":[{"name":"Memcached","slug":"Memcached","permalink":"http://www.merlin4io.com/tags/Memcached/"}]},{"title":"ThreadLocal初体验","slug":"ThreadLocal初体验","date":"2016-08-23T01:17:14.000Z","updated":"2017-08-31T07:41:56.000Z","comments":true,"path":"2016/08/23/ThreadLocal初体验/","link":"","permalink":"http://www.merlin4io.com/2016/08/23/ThreadLocal初体验/","excerpt":"网络上有很多关于ThreadLocal的介绍，有很多介绍使用场景，使用方法，以及源码的文章。这里只是简单的介绍一下。 ThreadLocal的定义ThreadLocal为变量在每个线程中都创建一个副本，所以每个线程只能访问自己内部的副本变量。在自己的线程内部共享，不同线程之间不会互相干扰。ThreadLocal是为了保证线程范围内的共享数据而生。ThreadLocal提供了一种访问某个变量的特殊方式：访问到的变量属于当前线程，即保证每个线程的变量不一样，而同一个线程在任何地方都可以拿到这个线程变量，这就是所谓的线程隔离。如果要使用ThreadLocal，通常定义为private static类型，最好是定义为private static final类型。","text":"网络上有很多关于ThreadLocal的介绍，有很多介绍使用场景，使用方法，以及源码的文章。这里只是简单的介绍一下。 ThreadLocal的定义ThreadLocal为变量在每个线程中都创建一个副本，所以每个线程只能访问自己内部的副本变量。在自己的线程内部共享，不同线程之间不会互相干扰。ThreadLocal是为了保证线程范围内的共享数据而生。ThreadLocal提供了一种访问某个变量的特殊方式：访问到的变量属于当前线程，即保证每个线程的变量不一样，而同一个线程在任何地方都可以拿到这个线程变量，这就是所谓的线程隔离。如果要使用ThreadLocal，通常定义为private static类型，最好是定义为private static final类型。 ThreaLocal使用场景什么样的场景下适合使用ThreadLocal？ThreadLocal通常用来共享数据，当你想在多个方法中使用某个变量，这个变量是当前线程的状态，其它线程不依赖这个变量，你第一时间想到的就是把变量定义在方法内部，然后再方法之间传递参数来使用，这个方法能解决问题，但是有个烦人的地方就是，每个方法都需要声明形参，多处声明，多处调用。影响代码的美观和维护。有没有一种方法能将变量像private static形式来访问呢？这样在类的任何一处地方就都能使用。这个时候ThreadLocal大显身手了。 另一方面ThreadLocal做线程隔离，线程之间不共享的数据可以放倒ThreadLocal里面去。 使用ThreadLocal要注意哪些问题？自己声明的线程变量，使用完之后一定要清理，处理好战场，如果每次都是新建一个线程，是可以不清理，但是一般情况下都会使用线程池，使用了线程池，就要保证自己拿到线程的时候，线程变量要初始化，也就是清除原先使用该线程的地方没有清理战场，导致自己的程序异常执行，自己使用完之后要自觉的清理战场。如果是一个比较大的模块使用线程变量，比如过，牵扯到N多个类，都会使用到，那么最好是写一个线程变量的管理类（类似上下文的概念），每个使用的地方都去上下文环境中去拿就行了，或者往上下文环境中存数据就可以了。具体怎么使用，怎么初始化，最终怎么清理，使用的地方可以不关注，全局控制的地方，也就是入口和出口会控制这些东西，另外清理动作一定要放在finanly里面去执行，线程内出现任何异常都要去处理战场，处理完之后可以把异常继续抛出去。 或许有人会问单线程适不适合使用呢？ 在我看来，这没有什么区别，想再线程内部共享数据和多线程没有关系，只要处理好线程内部的战场就好了。 具体的使用方式，方法这里就不罗列代码了，不过可以有几个相关的类可以做参考 如下代码： package com.cydeer.demo.settle; import java.util.ArrayList; import java.util.List; /** * Created by zhangsong on 16/8/15. * 线程变量全局管理类 */ public class SettleContext { /** * 结算信息列表 */ private static ThreadLocal&lt;List&lt;object&gt;&gt; stmtInfos = new ThreadLocal&lt;&gt;(); /** * 结算过程信息列表 */ private static ThreadLocal&lt;List&lt;object&gt;&gt; formulaInfos = new ThreadLocal&lt;&gt;(); /** * 添加 结算主体信息 * * @param stmtInfo */ public static void addStmtInfo(Object stmtInfo) { if (stmtInfo == null) { return; } List&lt;Object&gt; stmtInfoList = stmtInfos.get(); if (stmtInfoList == null) { stmtInfoList = new ArrayList&lt;&gt;(); stmtInfos.set(stmtInfoList); } stmtInfoList.add(stmtInfo); } /** * 获取 结算主体信息 * * @return */ public static List&lt;Object&gt; getStmtInfo() { return stmtInfos.get(); } /** * @param formulaInfo */ public static void addSettleFormulaInfo(Object formulaInfo) { if (formulaInfo == null) { return; } List&lt;Object&gt; formulaInfoList = formulaInfos.get(); if (formulaInfoList == null) { formulaInfoList = new ArrayList&lt;&gt;(); formulaInfos.set(formulaInfoList); } formulaInfoList.add(formulaInfo); } /** * 获取 计算过程 * * @return */ public static List&lt;Object&gt; getSettleFormulaInfo() { return formulaInfos.get(); } /** * 清空数据 */ public static void clear() { stmtInfos.remove(); formulaInfos.remove(); } public static void init() { clear(); } } 使用的地方只要调用： 使用之初初始化： SettleContext.init(); 存储数据： SettleContext.addStmtInfo(object); 获取数据： SettleContext.getStmtInfo(); 使用完之后： SettleContext.clear(); 代码： try { SettleContext.init(); System.out.println(&quot;各种执行逻辑封装数据&quot;); transactionTemplate.execute(new TransactionCallback&lt;Boolean&gt;() { @Override public Boolean doInTransaction(TransactionStatus transactionStatus) { System.out.println(&quot;获取数据,对数据持久化,或者再加工&quot;); return Boolean.TRUE; } }); } catch (Exception e) { throw e; } finally { SettleContext.clear(); } 最后的话： 一般情况下ThreadLocal不这么用，因为，这样，其他人就能够修改内部具体的内容了，好的使用方法是，存储对应的数据，然后提供接口来获取，只能获取存储数据的人想要提供的数据。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.merlin4io.com/tags/Java/"},{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"http://www.merlin4io.com/tags/ThreadLocal/"}]},{"title":"Java设计模式之单例","slug":"Java设计模式之单例","date":"2016-08-21T13:31:41.000Z","updated":"2017-08-31T07:29:37.000Z","comments":true,"path":"2016/08/21/Java设计模式之单例/","link":"","permalink":"http://www.merlin4io.com/2016/08/21/Java设计模式之单例/","excerpt":"接触Java的第一个设计模式大多数人都是单例，但是如果写一个完美的单例却不是随手拈来的事，要考虑的事情还是有的。 第一个版本： 最简单,但是 可能会耗费性能,不需要的时候其实不用创建（特别是创建需要分配较大内存的时候） /** * Created by zhangsong on 16/6/8. * &lt;p&gt; * 最简单,但是 可能会耗费性能,不需要的时候其实不用创建 */ public class Singleton { private final static Singleton instance = new Singleton(); private Singleton() { } public static Singleton getInstance() { return instance; } }","text":"接触Java的第一个设计模式大多数人都是单例，但是如果写一个完美的单例却不是随手拈来的事，要考虑的事情还是有的。 第一个版本： 最简单,但是 可能会耗费性能,不需要的时候其实不用创建（特别是创建需要分配较大内存的时候） /** * Created by zhangsong on 16/6/8. * &lt;p&gt; * 最简单,但是 可能会耗费性能,不需要的时候其实不用创建 */ public class Singleton { private final static Singleton instance = new Singleton(); private Singleton() { } public static Singleton getInstance() { return instance; } } 第二个版本： 存在致命的问题。当有多个线程并行调用 getInstance() 的时候，就会创建多个实例。也就是说在多线程下不能正常工作。 /** * Created by zhangsong on 16/6/8. * &lt;p&gt; * 最直接但是不安全 */ public class SimpleSingleton { private static SimpleSingleton instance; private SimpleSingleton() { } public static SimpleSingleton getInstance() { if (instance == null) { instance = new SimpleSingleton(); } return instance; } } 第三个版本： 双重检验锁 注意点： instance = new SeqSingleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。 给 instance 分配内存 调用 Singleton 的构造函数来初始化成员变量 将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了） 但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。所以instance上面加了volatile。 然后说到volatile，volatile主要有两点，内存可见，防止指令重排序。而这里使用到的是防止重排序，当然，你可以不了解其中原理，一直这样写。但是当别人问起，你总要知道原因的。 代码： /** * Created by zhangsong on 16/6/8. * &lt;p&gt; 双锁校验,安全,使用才会创建 * 安全模式 */ public class SeqSingleton { private volatile static SeqSingleton instance; private SeqSingleton() { } public static SeqSingleton getInstance() { if (instance == null) { synchronized (SeqSingleton.class) { if (instance == null) { instance = new SeqSingleton(); } } } return instance; } } 推荐使用版本： 使用静态内部类，线程安全，又是使用的时候才会初始化。 /** * Created by zhangsong on 16/6/8. */ public class FactorySingleton { private FactorySingleton() { } private static class SingletonFactory { private final static FactorySingleton instance = new FactorySingleton(); } public static FactorySingleton getInstance() { return SingletonFactory.instance; } }","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.merlin4io.com/tags/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"http://www.merlin4io.com/tags/设计模式/"},{"name":"单例","slug":"单例","permalink":"http://www.merlin4io.com/tags/单例/"}]},{"title":"Java实现Callback","slug":"Java实现Callback","date":"2016-08-21T02:28:59.000Z","updated":"2017-08-31T07:29:44.000Z","comments":true,"path":"2016/08/21/Java实现Callback/","link":"","permalink":"http://www.merlin4io.com/2016/08/21/Java实现Callback/","excerpt":"Callback(回调)，在不侵入别人代码的情况下实现别人功能完成以后执行自己的代码，可以分为同步回调和一部回调。同步回调一般会有回调的返回结果，调用的方法和回调返回参数一样。异步调用一般会在方法内新启线程来执行业务逻辑。","text":"Callback(回调)，在不侵入别人代码的情况下实现别人功能完成以后执行自己的代码，可以分为同步回调和一部回调。同步回调一般会有回调的返回结果，调用的方法和回调返回参数一样。异步调用一般会在方法内新启线程来执行业务逻辑。eg: package com.cydeer.demo.callback.api; /** * Created by zhangsong on 16/8/21. */ public interface CallBack&lt;T&gt; { T invoke(); } 业务处理方： 接口： package com.cydeer.demo.callback.api; /** * Created by zhangsong on 16/8/21. * 业务执行器 接口 */ public interface SettleExecutor { /** * 异步执行 * * @param o * @param callBack * @param &lt;&gt; * @return */ void asyncExecute(Object o, CallBack&lt;?&gt; callBack); /** * 同步执行 * * @param o * @param callBack * @param &lt;T&gt; * @return */ &lt;T&gt; T syncExecute(Object o, CallBack&lt;T&gt; callBack); } 实现： package com.cydeer.demo.callback.impl; import com.cydeer.demo.callback.api.CallBack; import com.cydeer.demo.callback.api.SettleExecutor; /** * Created by zhangsong on 16/8/21. * 业务执行器实现 */ public class SettleExecutorImpl implements SettleExecutor { @Override public void asyncExecute(Object o, CallBack&lt;?&gt; callBack) { // 使用新线程异步执行 new Thread(new Runnable() { @Override public void run() { execute(o); callBack.invoke(); } }).start(); } @Override public &lt;T&gt; T syncExecute(Object o, CallBack&lt;T&gt; callBack) { execute(o); return callBack.invoke(); } /** * 实际的业务执行逻辑 * * @param o */ private void execute(Object o) { System.out.println(&quot;参数检查&quot;); System.out.println(&quot;业务逻辑一&quot;); System.out.println(&quot;业务逻辑二&quot;); System.out.println(&quot;业务逻辑执行结束&quot;); } } 调用方： package com.cydeer.demo.callback.client; import com.cydeer.demo.callback.api.CallBack; import com.cydeer.demo.callback.api.SettleExecutor; import com.cydeer.demo.callback.impl.SettleExecutorImpl; /** * Created by zhangsong on 16/8/21. */ public class CallbackClient { public static void main(String[] args) { Object param = new Object(); System.out.println(&quot;执行调用方自己的业务逻辑&quot;); SettleExecutor settleExecutor = new SettleExecutorImpl(); // 异步调用,拿不到返回结果 settleExecutor.asyncExecute(param, new CallBack&lt;Boolean&gt;() { @Override public Boolean invoke() { System.out.println(&quot;第三方业务逻辑调用完成过,执行调用方自己的业务逻辑&quot;); return Boolean.TRUE; } }); // 同步调用 可以拿到返回结果,返回结果由调用方决定,返回回调函数中的返回类型 Object result = settleExecutor.syncExecute(param, new CallBack&lt;Object&gt;() { @Override public Object invoke() { System.out.println(&quot;第三方业务逻辑调用完成过,执行调用方自己的业务逻辑&quot;); return new Object(); } }); } } 总结： 使用场景为： 希望别人的业务逻辑之行完之后，然后继续执行自己的一段业务逻辑，比如，统计业务处理放的成功率等。 如果回调函数以来业务处理方的处理结果，可以把业务方的处理结果当作回调参数。 代码地址：https://github.com/xia-zhou/demo-cydeer.git 在callback包下面","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.merlin4io.com/tags/Java/"},{"name":"Callback","slug":"Callback","permalink":"http://www.merlin4io.com/tags/Callback/"}]},{"title":"Zookeeper 学习笔记（一）","slug":"Zookeeper-学习笔记（一）","date":"2016-08-14T08:00:07.000Z","updated":"2017-02-06T06:24:41.000Z","comments":true,"path":"2016/08/14/Zookeeper-学习笔记（一）/","link":"","permalink":"http://www.merlin4io.com/2016/08/14/Zookeeper-学习笔记（一）/","excerpt":"","text":"zookeeper，一个分布式服务协调框架，分布式数据一致性的一个方案。 可以认为是一种数据库，数据库的结构为树形文件系统类似，树有节点，节点有子节点和数据。节点分为持久节点，临时节点，每种节点又可分为无序和有序。临时节点在zk客户端和zk服务端断开的时候自动删除。持久节点不会因为客户端的断开而删除，服务端的每个节点的删除，更新，都会发布对应的事件，关注事件的人，可以根据事件类型做不同的处理。节点的事件为一次性事件，事件触发后失效，如果想要继续关注，就需要添加新的监测点。 可以满足： 简单的数据类型，可以构建集群，顺序访问，高性能。 集群角色： leader，follower，observer。 基本概念 会话，数据节点，版本，watcher，acl，zab协议，原子消息广播协议 目前项目中zookeeper作为dubbo的注册中心，统一权限管理系统的注册中心，分布式配置的注册中心。 在dubbo中的使用： 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。 注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外 注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者 注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表 zookeeper服务端： 可以支持集群和单点。 下载zookeeper包，解压，需要java环境。 zookeeper客户端： zkCli.sh -server ip:port 开源的客户端有zkClient,curator。 zookeeper可以实现分布式锁","categories":[],"tags":[]}]}